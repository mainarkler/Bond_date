import streamlit as st
import pandas as pd
import requests
import xml.etree.ElementTree as ET
from datetime import datetime, timedelta
from io import BytesIO, StringIO
import os
import csv
import re
from concurrent.futures import ThreadPoolExecutor, as_completed

# === –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã ===
st.set_page_config(page_title="–†–ï–ü–û –ø—Ä–µ—Ç—Ä–µ–π–¥", page_icon="üìà", layout="wide")
st.title("üìà –†–ï–ü–û –ø—Ä–µ—Ç—Ä–µ–π–¥")

# === Session state ===
if "results" not in st.session_state:
    st.session_state["results"] = None
if "file_loaded" not in st.session_state:
    st.session_state["file_loaded"] = False
if "last_file_name" not in st.session_state:
    st.session_state["last_file_name"] = None

# === –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –†–ï–ü–û ===
st.subheader("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –†–ï–ü–û")
if "overnight" not in st.session_state:
    st.session_state["overnight"] = False
if "extra_days" not in st.session_state:
    st.session_state["extra_days"] = 2

if st.button("üîÑ –û—á–∏—Å—Ç–∏—Ç—å —Ñ–æ—Ä–º—É"):
    st.session_state["overnight"] = False
    st.session_state["extra_days"] = 2
    st.session_state["results"] = None
    st.session_state["file_loaded"] = False
    st.session_state["last_file_name"] = None
    st.rerun()

overnight = st.checkbox("Overnight –†–ï–ü–û", key="overnight")
extra_days_input = st.number_input(
    "–î–Ω–µ–π –†–ï–ü–û:",
    min_value=2,
    max_value=366,
    step=1,
    disabled=st.session_state["overnight"],
    key="extra_days",
)
if st.session_state["overnight"]:
    st.markdown("<span style='color:gray'>–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–Ω–∏ –æ—Ç–∫–ª—é—á–µ–Ω—ã –ø—Ä–∏ –≤–∫–ª—é—á–µ–Ω–Ω–æ–º Overnight</span>", unsafe_allow_html=True)
days_threshold = 2 if st.session_state["overnight"] else 1 + st.session_state["extra_days"]
st.write(f"–¢–µ–∫—É—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≥—Ä–∞–Ω–∏—Ü—ã –≤—ã–ø–ª–∞—Ç: {days_threshold} –¥–Ω.")

# === –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ —á—Ç–µ–Ω–∏–µ CSV ===
def safe_read_csv(path):
    if not os.path.exists(path):
        st.warning(f"‚ö†Ô∏è –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {path}")
        return pd.DataFrame()
    try:
        with open(path, "r", encoding="utf-8-sig") as f:
            content = f.read()
        content = content.replace('\r\n', '\n').strip()
        sample = content[:2048]
        try:
            dialect = csv.Sniffer().sniff(sample, delimiters=[",", ";", "\t"])
            sep = dialect.delimiter
        except Exception:
            sep = ","
        df = pd.read_csv(StringIO(content), sep=sep, dtype=str)
        df.columns = [c.strip().upper() for c in df.columns]
        return df
    except Exception as e:
        st.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ {os.path.basename(path)}: {e}")
        return pd.DataFrame()

# === MOEX API session ===
session = requests.Session()
session.headers.update({"User-Agent": "python-requests/iss-moex-script"})

# === –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ XML TQOB –∏ TQCB ===
@st.cache_data(ttl=3600)
def fetch_board_xml(board: str):
    url = f"https://iss.moex.com/iss/engines/stock/markets/bonds/boards/{board.lower()}/securities.xml?marketprice_board=3&iss.meta=off"
    try:
        r = session.get(url, timeout=20)
        r.raise_for_status()
        xml_content = r.content.decode("utf-8", errors="ignore")
        xml_content = re.sub(r'\sxmlns="[^"]+"', "", xml_content, count=1)
        root = ET.fromstring(xml_content)
        mapping = {}
        for el in root.iter():
            if el.tag.lower().endswith("row"):
                attrs = {k.upper(): v for k, v in el.attrib.items()}
                isin = attrs.get("ISIN", "").strip().upper()
                secid = attrs.get("SECID", "").strip().upper()
                emitterid = attrs.get("EMITTERID", "").strip()
                if isin:
                    mapping[isin] = {"SECID": secid or None, "EMITTERID": emitterid or None, **attrs}
        return mapping
    except Exception:
        return {}

TQOB_MAP = fetch_board_xml("tqob")
TQCB_MAP = fetch_board_xml("tqcb")

# === –§—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞ —ç–º–∏—Ç–µ–Ω—Ç–∞ –∏ SECID ===
@st.cache_data(ttl=3600)
def fetch_emitter_and_secid(isin: str):
    isin = str(isin).strip().upper()
    if not isin:
        return None, None
    emitter_id = None
    secid = None

    # 1) JSON –ø–æ ISIN
    try:
        url = f"https://iss.moex.com/iss/securities/{isin}.json"
        r = session.get(url, timeout=10)
        r.raise_for_status()
        data = r.json()
        securities = data.get("securities", {})
        cols = securities.get("columns", [])
        rows = securities.get("data", [])
        if rows:
            first = rows[0]
            col_map = {c.upper(): i for i, c in enumerate(cols)}
            if "EMITTER_ID" in col_map:
                emitter_id = first[col_map.get("EMITTER_ID")]
            elif "EMITTERID" in col_map:
                emitter_id = first[col_map.get("EMITTERID")]
            if "SECID" in col_map:
                secid = first[col_map.get("SECID")]
    except Exception:
        pass

    # 2) XML –ø–æ ISIN (fallback)
    if not secid:
        try:
            url = f"https://iss.moex.com/iss/securities/{isin}.xml?iss.meta=off"
            r = session.get(url, timeout=10)
            r.raise_for_status()
            xml_content = r.content.decode("utf-8", errors="ignore")
            xml_content = re.sub(r'\sxmlns="[^"]+"', "", xml_content, count=1)
            root = ET.fromstring(xml_content)
            for node in root.iter():
                name_attr = (node.attrib.get("name") or "").upper()
                val_attr = node.attrib.get("value") or ""
                if name_attr == "SECID":
                    secid = val_attr
                elif name_attr == "EMITTER_ID" or name_attr == "EMITTERID":
                    emitter_id = val_attr
        except Exception:
            pass

    # 3) XML-–±–æ—Ä–¥—ã (TQOB/TQCB)
    if not secid:
        m = TQOB_MAP.get(isin) or TQCB_MAP.get(isin)
        if m:
            secid = m.get("SECID")
            if not emitter_id:
                emitter_id = m.get("EMITTERID")

    return emitter_id, secid

# === –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö ===

def _fmt_date(val):
    if val is None or (isinstance(val, float) and pd.isna(val)):
        return None
    try:
        return pd.to_datetime(val).strftime("%Y-%m-%d")
    except Exception:
        return None

def _next_future_date_from_dataframe(df, possible_cols):
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –±–ª–∏–∂–∞–π—à—É—é –¥–∞—Ç—É >= today –∏–∑ —É–∫–∞–∑–∞–Ω–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ df.
    –ï—Å–ª–∏ –Ω–∞–π–¥–µ–Ω–æ ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä–æ–∫—É YYYY-MM-DD, –∏–Ω–∞—á–µ None.
    """
    today = pd.to_datetime(datetime.today().date())
    candidates = []
    for col in possible_cols:
        if col in df.columns:
            try:
                s = pd.to_datetime(df[col], errors="coerce")
                s = s[s >= today]
                if not s.empty:
                    candidates.append(s.min())
            except Exception:
                pass
    if not candidates:
        return None
    nxt = min(candidates)
    return nxt.strftime("%Y-%m-%d")

def _any_future_date_in_df(df):
    """
    –ü–æ–∏—Å–∫ –±–ª–∏–∂–∞–π—à–µ–π –¥–∞—Ç—ã >= today –ø–æ –≤—Å–µ–º –∫–æ–ª–æ–Ω–∫–∞–º (fallback).
    """
    today = pd.to_datetime(datetime.today().date())
    cand = []
    for col in df.columns:
        try:
            s = pd.to_datetime(df[col], errors="coerce")
            s = s[s >= today]
            if not s.empty:
                cand.append(s.min())
        except Exception:
            pass
    if not cand:
        return None
    return min(cand).strftime("%Y-%m-%d")

def fetch_coupons_by_identifier(identifier):
    """
    –ü–æ–ø—ã—Ç–∫–∞ –ø–æ–ª—É—á–∏—Ç—å coupons —á–µ—Ä–µ–∑ bondization/{identifier}.json
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (coupon_date, record_date) ‚Äî —Å—Ç—Ä–æ–∫–∏ YYYY-MM-DD –∏–ª–∏ None.
    """
    try:
        url_coupons = f"https://iss.moex.com/iss/statistics/engines/stock/markets/bonds/bondization/{identifier}.json?iss.only=coupons&iss.meta=off"
        r = session.get(url_coupons, timeout=12)
        r.raise_for_status()
        data = r.json()
        coupons = data.get("coupons", {}).get("data", [])
        cols = data.get("coupons", {}).get("columns", [])
        if coupons and cols:
            df = pd.DataFrame(coupons, columns=cols)
            df.columns = [c.upper() for c in df.columns]
            # –≤–æ–∑–º–æ–∂–Ω—ã–µ –∏–º–µ–Ω–∞ –∫–æ–ª–æ–Ω–æ–∫
            possible_coupon_cols = [c for c in df.columns if "COUPON" in c and "DATE" in c]
            possible_record_cols = [c for c in df.columns if "RECORD" in c and "DATE" in c]
            coupon_date = _next_future_date_from_dataframe(df, possible_coupon_cols) or _any_future_date_in_df(df)
            record_date = _next_future_date_from_dataframe(df, possible_record_cols)
            return coupon_date, record_date
    except Exception:
        pass
    return None, None

def fetch_info_by_isin(isin):
    """
    –ß–∞—Å—Ç—å 1: –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ —Å—Ç—Ä–æ–≥–æ –ø–æ ISIN.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç dict —Å –Ω—É–∂–Ω—ã–º–∏ –ø–æ–ª—è–º–∏ (–∑–Ω–∞—á–µ–Ω–∏—è –º–æ–≥—É—Ç –±—ã—Ç—å None/–ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏).
    """
    result = {
        "ISIN": isin,
        "–ö–æ–¥ —ç–º–∏—Ç–µ–Ω—Ç–∞": "",
        "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞": "",
        "–î–∞—Ç–∞ –ø–æ–≥–∞—à–µ–Ω–∏—è": None,
        "–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Put": None,
        "–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Call": None,
        "–î–∞—Ç–∞ —Ñ–∏–∫—Å–∞—Ü–∏–∏ –∫—É–ø–æ–Ω–∞": None,
        "–î–∞—Ç–∞ –∫—É–ø–æ–Ω–∞": None,
    }

    isin = str(isin).strip().upper()
    if not isin:
        return result

    # –ü–æ–ø—Ä–æ–±—É–µ–º securities/{isin}.json
    try:
        url = f"https://iss.moex.com/iss/securities/{isin}.json"
        r = session.get(url, timeout=10)
        r.raise_for_status()
        data = r.json()
        sec = data.get("securities", {})
        cols = sec.get("columns", [])
        rows = sec.get("data", [])
        if rows and cols:
            row = rows[0]
            col_map = {c.upper(): i for i, c in enumerate(cols)}
            if "SECNAME" in col_map:
                result["–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞"] = row[col_map["SECNAME"]] or result["–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞"]
            elif "SEC_NAME" in col_map:
                result["–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞"] = row[col_map["SEC_NAME"]] or result["–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞"]

            if "EMITTER_ID" in col_map:
                result["–ö–æ–¥ —ç–º–∏—Ç–µ–Ω—Ç–∞"] = row[col_map["EMITTER_ID"]] or result["–ö–æ–¥ —ç–º–∏—Ç–µ–Ω—Ç–∞"]
            elif "EMITTERID" in col_map:
                result["–ö–æ–¥ —ç–º–∏—Ç–µ–Ω—Ç–∞"] = row[col_map["EMITTERID"]] or result["–ö–æ–¥ —ç–º–∏—Ç–µ–Ω—Ç–∞"]

            if "MATDATE" in col_map:
                result["–î–∞—Ç–∞ –ø–æ–≥–∞—à–µ–Ω–∏—è"] = _fmt_date(row[col_map["MATDATE"]])
            elif "MATURITYDATE" in col_map:
                result["–î–∞—Ç–∞ –ø–æ–≥–∞—à–µ–Ω–∏—è"] = _fmt_date(row[col_map["MATURITYDATE"]])
    except Exception:
        pass

    # –ö—É–ø–æ–Ω—ã –ø–æ ISIN
    coupon_date, record_date = fetch_coupons_by_identifier(isin)
    result["–î–∞—Ç–∞ –∫—É–ø–æ–Ω–∞"] = coupon_date
    result["–î–∞—Ç–∞ —Ñ–∏–∫—Å–∞—Ü–∏–∏ –∫—É–ø–æ–Ω–∞"] = record_date

    return result

def fetch_info_by_secid(secid):
    """
    –ß–∞—Å—Ç—å 2: –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ —Å—Ç—Ä–æ–≥–æ –ø–æ SECID (–≤—Å–µ –∑–∞–ø—Ä–æ—Å—ã –ø–æ secid).
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç dict —Å –Ω—É–∂–Ω—ã–º–∏ –ø–æ–ª—è–º–∏.
    """
    result = {
        "ISIN": None,  # secid-—á–∞—Å—Ç—å –Ω–µ –≤—Å–µ–≥–¥–∞ –∑–Ω–∞–µ—Ç ISIN, –≤–Ω–µ—à–Ω—è—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–∏—Å–≤–æ–∏—Ç ISIN –ø—Ä–∏ –≤–æ–∑–≤—Ä–∞—Ç–µ
        "–ö–æ–¥ —ç–º–∏—Ç–µ–Ω—Ç–∞": "",
        "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞": "",
        "–î–∞—Ç–∞ –ø–æ–≥–∞—à–µ–Ω–∏—è": None,
        "–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Put": None,
        "–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Call": None,
        "–î–∞—Ç–∞ —Ñ–∏–∫—Å–∞—Ü–∏–∏ –∫—É–ø–æ–Ω–∞": None,
        "–î–∞—Ç–∞ –∫—É–ø–æ–Ω–∞": None,
    }

    if not secid:
        return result

    # –ü–æ–ø—Ä–æ–±—É–µ–º engines/.../securities/{secid}.json
    try:
        url_info = f"https://iss.moex.com/iss/engines/stock/markets/bonds/securities/{secid}.json"
        r = session.get(url_info, timeout=12)
        r.raise_for_status()
        data_info = r.json()
        sec = data_info.get("securities", {})
        cols = sec.get("columns", [])
        rows = sec.get("data", [])
        if rows and cols:
            row = rows[0]
            col_map = {c.upper(): i for i, c in enumerate(cols)}
            if "SECNAME" in col_map:
                result["–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞"] = row[col_map["SECNAME"]] or result["–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞"]
            elif "SEC_NAME" in col_map:
                result["–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞"] = row[col_map["SEC_NAME"]] or result["–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞"]

            # –ú–∞—Ç–¥–∞—Ç–∞ –∏ –æ–ø—Ü–∏–æ–Ω—ã
            if "MATDATE" in col_map:
                result["–î–∞—Ç–∞ –ø–æ–≥–∞—à–µ–Ω–∏—è"] = _fmt_date(row[col_map["MATDATE"]])
            if "PUTOPTIONDATE" in col_map:
                result["–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Put"] = _fmt_date(row[col_map["PUTOPTIONDATE"]])
            if "CALLOPTIONDATE" in col_map:
                result["–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Call"] = _fmt_date(row[col_map["CALLOPTIONDATE"]])

            if "EMITTERID" in col_map:
                result["–ö–æ–¥ —ç–º–∏—Ç–µ–Ω—Ç–∞"] = row[col_map["EMITTERID"]] or result["–ö–æ–¥ —ç–º–∏—Ç–µ–Ω—Ç–∞"]
            elif "EMITTER_ID" in col_map:
                result["–ö–æ–¥ —ç–º–∏—Ç–µ–Ω—Ç–∞"] = row[col_map["EMITTER_ID"]] or result["–ö–æ–¥ —ç–º–∏—Ç–µ–Ω—Ç–∞"]
    except Exception:
        pass

    # –ö—É–ø–æ–Ω—ã –ø–æ SECID
    coupon_date, record_date = fetch_coupons_by_identifier(secid)
    result["–î–∞—Ç–∞ –∫—É–ø–æ–Ω–∞"] = coupon_date
    result["–î–∞—Ç–∞ —Ñ–∏–∫—Å–∞—Ü–∏–∏ –∫—É–ø–æ–Ω–∞"] = record_date

    return result

# === –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è: —Å–Ω–∞—á–∞–ª–∞ ISIN, –µ—Å–ª–∏ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç ‚Äî –∏—Å–∫–∞—Ç—å SECID –∏ –∑–∞–ø—Ä–æ—Å –ø–æ SECID ===
@st.cache_data(ttl=3600)
def get_bond_data(isin):
    isin = str(isin).strip().upper()
    base_template = {
        "ISIN": isin,
        "–ö–æ–¥ —ç–º–∏—Ç–µ–Ω—Ç–∞": "",
        "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞": "",
        "–î–∞—Ç–∞ –ø–æ–≥–∞—à–µ–Ω–∏—è": None,
        "–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Put": None,
        "–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Call": None,
        "–î–∞—Ç–∞ —Ñ–∏–∫—Å–∞—Ü–∏–∏ –∫—É–ø–æ–Ω–∞": None,
        "–î–∞—Ç–∞ –∫—É–ø–æ–Ω–∞": None,
    }

    if not isin:
        return base_template

    # --- –ß–∞—Å—Ç—å 1: –ø–æ–∏—Å–∫ –∏ —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –ø–æ ISIN ---
    res_isin = fetch_info_by_isin(isin)

    # —Å—á–∏—Ç–∞–µ–º, —á—Ç–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç —É—Å–ø–µ—à–µ–Ω –µ—Å–ª–∏ –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã –∏–º—è –∏–ª–∏ –º–∞—Ç–¥–∞—Ç–∞ –∏–ª–∏ –±–ª–∏–∂–∞–π—à–∏–π –∫—É–ø–æ–Ω
    has_nonempty = any([
        res_isin.get("–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞"),
        res_isin.get("–î–∞—Ç–∞ –ø–æ–≥–∞—à–µ–Ω–∏—è"),
        res_isin.get("–î–∞—Ç–∞ –∫—É–ø–æ–Ω–∞"),
        res_isin.get("–ö–æ–¥ —ç–º–∏—Ç–µ–Ω—Ç–∞"),
    ])

    if has_nonempty:
        # –∑–∞–ø–æ–ª–Ω—è–µ–º —à–∞–±–ª–æ–Ω –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º (ISIN —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω)
        out = base_template.copy()
        out.update({
            "–ö–æ–¥ —ç–º–∏—Ç–µ–Ω—Ç–∞": res_isin.get("–ö–æ–¥ —ç–º–∏—Ç–µ–Ω—Ç–∞") or "",
            "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞": res_isin.get("–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞") or "",
            "–î–∞—Ç–∞ –ø–æ–≥–∞—à–µ–Ω–∏—è": res_isin.get("–î–∞—Ç–∞ –ø–æ–≥–∞—à–µ–Ω–∏—è"),
            "–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Put": res_isin.get("–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Put"),
            "–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Call": res_isin.get("–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Call"),
            "–î–∞—Ç–∞ —Ñ–∏–∫—Å–∞—Ü–∏–∏ –∫—É–ø–æ–Ω–∞": res_isin.get("–î–∞—Ç–∞ —Ñ–∏–∫—Å–∞—Ü–∏–∏ –∫—É–ø–æ–Ω–∞"),
            "–î–∞—Ç–∞ –∫—É–ø–æ–Ω–∞": res_isin.get("–î–∞—Ç–∞ –∫—É–ø–æ–Ω–∞"),
        })
        return out

    # --- –ß–∞—Å—Ç—å 2: –µ—Å–ª–∏ –ø–æ ISIN –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –Ω–∞–π—Ç–∏ SECID –∏ –≤–∑—è—Ç—å –¥–∞–Ω–Ω—ã–µ –ø–æ SECID ---
    emitter_id, secid = fetch_emitter_and_secid(isin)

    if secid:
        res_secid = fetch_info_by_secid(secid)
        out = base_template.copy()
        out.update({
            "–ö–æ–¥ —ç–º–∏—Ç–µ–Ω—Ç–∞": res_secid.get("–ö–æ–¥ —ç–º–∏—Ç–µ–Ω—Ç–∞") or emitter_id or "",
            "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞": res_secid.get("–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞") or "",
            "–î–∞—Ç–∞ –ø–æ–≥–∞—à–µ–Ω–∏—è": res_secid.get("–î–∞—Ç–∞ –ø–æ–≥–∞—à–µ–Ω–∏—è"),
            "–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Put": res_secid.get("–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Put"),
            "–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Call": res_secid.get("–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Call"),
            "–î–∞—Ç–∞ —Ñ–∏–∫—Å–∞—Ü–∏–∏ –∫—É–ø–æ–Ω–∞": res_secid.get("–î–∞—Ç–∞ —Ñ–∏–∫—Å–∞—Ü–∏–∏ –∫—É–ø–æ–Ω–∞"),
            "–î–∞—Ç–∞ –∫—É–ø–æ–Ω–∞": res_secid.get("–î–∞—Ç–∞ –∫—É–ø–æ–Ω–∞"),
        })
        return out

    # --- fallback: –µ—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à–ª–∏ –Ω–∏ –ø–æ ISIN –Ω–∏ –ø–æ SECID, –ø—Ä–æ–±—É–µ–º –±–æ—Ä–¥—ã TQOB/TQCB (–µ—Å–ª–∏ –µ—Å—Ç—å) ---
    m = TQOB_MAP.get(isin) or TQCB_MAP.get(isin)
    if m:
        out = base_template.copy()
        out.update({
            "–ö–æ–¥ —ç–º–∏—Ç–µ–Ω—Ç–∞": m.get("EMITTERID") or "",
            "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞": m.get("SECNAME") or m.get("NAME") or "",
            "–î–∞—Ç–∞ –ø–æ–≥–∞—à–µ–Ω–∏—è": _fmt_date(m.get("MATDATE") or m.get("MATDATE")),
            "–î–∞—Ç–∞ —Ñ–∏–∫—Å–∞—Ü–∏–∏ –∫—É–ø–æ–Ω–∞": _fmt_date(m.get("RECORDDATE") or m.get("RECORD_DATE") or m.get("RECORD")),
            "–î–∞—Ç–∞ –∫—É–ø–æ–Ω–∞": _fmt_date(m.get("COUPONDATE") or m.get("COUPON_DATE") or m.get("COUPON")),
        })
        return out

    # –ï—Å–ª–∏ —Å–æ–≤—Å–µ–º –Ω–∏—á–µ–≥–æ ‚Äî –≤–µ—Ä–Ω—É—Ç—å –ø—É—Å—Ç–æ–π —à–∞–±–ª–æ–Ω
    return base_template

# === –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ ===
def fetch_isins_parallel(isins):
    results = []
    with ThreadPoolExecutor(max_workers=10) as executor:
        future_to_isin = {executor.submit(get_bond_data, isin): isin for isin in isins}
        for future in as_completed(future_to_isin):
            data = future.result()
            if data:
                results.append(data)
    return results

# === –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –≤–≤–æ–¥–∞ ===
st.subheader("üì§ –ó–∞–≥—Ä—É–∑–∫–∞ –∏–ª–∏ –≤–≤–æ–¥ ISIN")
tab1, tab2 = st.tabs(["üìÅ –ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª", "‚úçÔ∏è –í–≤–µ—Å—Ç–∏ –≤—Ä—É—á–Ω—É—é"])

with tab1:
    uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ Excel –∏–ª–∏ CSV —Å –∫–æ–ª–æ–Ω–∫–æ–π ISIN", type=["xlsx", "xls", "csv"])

with tab2:
    isin_input = st.text_area("–í–≤–µ–¥–∏—Ç–µ –∏–ª–∏ –≤—Å—Ç–∞–≤—å—Ç–µ ISIN (—á–µ—Ä–µ–∑ Ctrl+V, –ø—Ä–æ–±–µ–ª –∏–ª–∏ –∑–∞–ø—è—Ç—É—é)", height=150)
    if st.button("üîç –ü–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –ø–æ –≤–≤–µ–¥—ë–Ω–Ω—ã–º ISIN"):
        raw_text = isin_input.strip()
        if raw_text:
            isins = re.split(r"[\s,;]+", raw_text)
            isins = [i.strip().upper() for i in isins if i.strip()]
            results = fetch_isins_parallel(isins)
            st.session_state["results"] = pd.DataFrame(results)
            st.success("‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω—ã!")

# === –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞ ===
if uploaded_file:
    if not st.session_state["file_loaded"] or uploaded_file.name != st.session_state["last_file_name"]:
        st.session_state["file_loaded"] = True
        st.session_state["last_file_name"] = uploaded_file.name
        try:
            if uploaded_file.name.lower().endswith(".csv"):
                df = pd.read_csv(uploaded_file, dtype=str)
            else:
                df = pd.read_excel(uploaded_file, dtype=str)
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞: {e}")
            st.stop()

        df.columns = [c.strip().upper() for c in df.columns]
        if "ISIN" not in df.columns:
            st.error("‚ùå –í —Ñ–∞–π–ª–µ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –∫–æ–ª–æ–Ω–∫–∞ 'ISIN'.")
            st.stop()
        isins = df["ISIN"].dropna().unique().tolist()
        isins = [str(x).strip().upper() for x in isins if str(x).strip()]
        results = fetch_isins_parallel(isins)
        st.session_state["results"] = pd.DataFrame(results)
        st.success("‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω—ã –∏–∑ —Ñ–∞–π–ª–∞!")

# === –ü–æ–¥–≥—Ä—É–∑–∫–∞ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∞ —ç–º–∏—Ç–µ–Ω—Ç–æ–≤ ===
@st.cache_data(ttl=3600)
def fetch_emitter_names():
    url = "https://raw.githubusercontent.com/mainarkler/Bond_date/refs/heads/main/Pifagr_name_with_emitter.csv"
    try:
        df_emitters = pd.read_csv(url, dtype=str)
        df_emitters.columns = [c.strip() for c in df_emitters.columns]
        return df_emitters
    except Exception:
        return pd.DataFrame(columns=["Issuer", "EMITTER_ID"])

df_emitters = fetch_emitter_names()

# === –°—Ç–∏–ª–∏–∑–∞—Ü–∏—è —Ç–∞–±–ª–∏—Ü—ã ===
def style_df(row):
    if pd.isna(row.get("–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞")) or row.get("–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞") in [None, "None", ""]:
        return ["background-color: DimGray; color: white"] * len(row)
    today = datetime.today().date()
    danger_threshold = today + timedelta(days=days_threshold)
    key_dates = ["–î–∞—Ç–∞ –ø–æ–≥–∞—à–µ–Ω–∏—è", "–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Put", "–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Call", "–î–∞—Ç–∞ —Ñ–∏–∫—Å–∞—Ü–∏–∏ –∫—É–ø–æ–Ω–∞", "–î–∞—Ç–∞ –∫—É–ø–æ–Ω–∞"]
    colors = ["" for _ in row]
    for i, col in enumerate(row.index):
        if col in key_dates and pd.notnull(row[col]):
            try:
                d = pd.to_datetime(row[col]).date()
                if d <= danger_threshold:
                    colors[i] = "background-color: Chocolate"
            except:
                pass
    if any(c == "background-color: Chocolate" for c in colors):
        colors = ["background-color: SandyBrown" if c == "" else c for c in colors]
    return colors

# === –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ===
if st.session_state["results"] is not None:
    df_res = st.session_state["results"].copy()

    if "–ö–æ–¥ —ç–º–∏—Ç–µ–Ω—Ç–∞" in df_res.columns and not df_emitters.empty:
        df_res = df_res.merge(df_emitters, how="left", left_on="–ö–æ–¥ —ç–º–∏—Ç–µ–Ω—Ç–∞", right_on="EMITTER_ID")
        df_res["–≠–º–∏—Ç–µ–Ω—Ç"] = df_res["Issuer"]
        df_res.drop(columns=["Issuer", "EMITTER_ID"], inplace=True, errors="ignore")

        cols = df_res.columns.tolist()
        if "–≠–º–∏—Ç–µ–Ω—Ç" in cols and "–ö–æ–¥ —ç–º–∏—Ç–µ–Ω—Ç–∞" in cols:
            cols.remove("–≠–º–∏—Ç–µ–Ω—Ç")
            idx = cols.index("–ö–æ–¥ —ç–º–∏—Ç–µ–Ω—Ç–∞")
            cols.insert(idx + 1, "–≠–º–∏—Ç–µ–Ω—Ç")
            df_res = df_res[cols]

        st.session_state["results"] = df_res
    else:
        st.warning("‚ö†Ô∏è –í –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ '–ö–æ–¥ —ç–º–∏—Ç–µ–Ω—Ç–∞' ‚Äî –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å–æ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–æ–º –ø—Ä–æ–ø—É—â–µ–Ω–æ.")

    st.dataframe(df_res.style.apply(style_df, axis=1), use_container_width=True)

    def to_excel(df):
        output = BytesIO()
        with pd.ExcelWriter(output, engine="openpyxl") as writer:
            df.to_excel(writer, index=False, sheet_name="–î–∞–Ω–Ω—ã–µ")
        return output.getvalue()

    st.download_button(
        label="üíæ –°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç (Excel)",
        data=to_excel(df_res),
        file_name="bond_data.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
    )
else:
    st.info("üëÜ –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –∏–ª–∏ –≤–≤–µ–¥–∏—Ç–µ ISIN-—ã –≤—Ä—É—á–Ω—É—é.")
