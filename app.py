
import csv
import math
import re
import time
import xml.etree.ElementTree as ET
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime, timedelta
from io import BytesIO, StringIO

import pandas as pd
import requests
import streamlit as st
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# ---------------------------
# Streamlit page setup
# ---------------------------
st.set_page_config(page_title="–†–ï–ü–û –ø—Ä–µ—Ç—Ä–µ–π–¥", page_icon="üìà", layout="wide")
st.title("üìà –†–ï–ü–û –ø—Ä–µ—Ç—Ä–µ–π–¥")

# ---------------------------
# Session state defaults
# ---------------------------
if "results" not in st.session_state:
    st.session_state["results"] = None
if "file_loaded" not in st.session_state:
    st.session_state["file_loaded"] = False
if "last_file_name" not in st.session_state:
    st.session_state["last_file_name"] = None
if "active_view" not in st.session_state:
    st.session_state["active_view"] = "home"

# ---------------------------
# Main navigation
# ---------------------------
def trigger_rerun():
    if hasattr(st, "rerun"):
        st.rerun()
    else:
        st.experimental_rerun()


if st.session_state["active_view"] != "home":
    if st.button("‚¨ÖÔ∏è –ù–∞ –≥–ª–∞–≤–Ω—É—é"):
        st.session_state["active_view"] = "home"
        trigger_rerun()

if st.session_state["active_view"] == "home":
    st.subheader("üè† –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é")
    col1, col2 = st.columns(2)
    with col1:
        st.markdown("### üìà –ü—Ä–µ—Ç—Ä–µ–π–¥ –†–ï–ü–û")
        st.caption("–ê–Ω–∞–ª–∏–∑ ISIN –∏ –∫–ª—é—á–µ–≤—ã—Ö –¥–∞—Ç –±—É–º–∞–≥ –¥–ª—è —Å–¥–µ–ª–æ–∫ –†–ï–ü–û.")
        if st.button("–û—Ç–∫—Ä—ã—Ç—å", key="open_repo", use_container_width=True):
            st.session_state["active_view"] = "repo"
            trigger_rerun()
    with col2:
        st.markdown("### üìÖ –ö–∞–ª–µ–Ω–¥–∞—Ä—å –≤—ã–ø–ª–∞—Ç")
        st.caption("–ó–∞–≥—Ä—É–∑–∫–∞ –ø–æ—Ä—Ç—Ñ–µ–ª—è –∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∫–∞–ª–µ–Ω–¥–∞—Ä—è –∫—É–ø–æ–Ω–æ–≤ –∏ –ø–æ–≥–∞—à–µ–Ω–∏–π.")
        if st.button("–û—Ç–∫—Ä—ã—Ç—å", key="open_calendar", use_container_width=True):
            st.session_state["active_view"] = "calendar"
            trigger_rerun()
    st.stop()

# ---------------------------
# HTTP session with retries
# ---------------------------
def build_http_session():
    session = requests.Session()
    retry_strategy = Retry(
        total=5,
        backoff_factor=0.8,
        status_forcelist=[429, 500, 502, 503, 504],
        allowed_methods=["GET", "POST"],
    )
    adapter = HTTPAdapter(max_retries=retry_strategy)
    session.mount("https://", adapter)
    session.mount("http://", adapter)
    session.headers.update({"User-Agent": "python-requests/iss-moex-script"})
    return session


HTTP_SESSION = build_http_session()


def request_get(url: str, timeout: int = 15):
    response = HTTP_SESSION.get(url, timeout=timeout)
    response.raise_for_status()
    return response


def parse_number(value):
    if value is None or (isinstance(value, float) and math.isnan(value)):
        return None
    if isinstance(value, (int, float)):
        return float(value)
    try:
        cleaned = str(value).strip().replace(" ", "").replace(",", ".")
        if cleaned == "":
            return None
        return float(cleaned)
    except Exception:
        return None


# ---------------------------
# Safe CSV/Excel reading helpers
# ---------------------------
def safe_read_csv_string(content: str) -> pd.DataFrame:
    content = content.replace("\r\n", "\n").strip()
    sample = content[:8192]
    try:
        dialect = csv.Sniffer().sniff(sample, delimiters=[",", ";", "\t"])
        sep = dialect.delimiter
    except Exception:
        sep = ","
    try:
        df = pd.read_csv(StringIO(content), sep=sep, dtype=str)
        df.columns = [c.strip().upper() for c in df.columns]
        return df
    except Exception:
        return pd.DataFrame()


def safe_read_filelike(uploaded_file) -> pd.DataFrame:
    name = uploaded_file.name
    try:
        if name.lower().endswith(".csv"):
            raw = uploaded_file.getvalue().decode("utf-8-sig")
            return safe_read_csv_string(raw)
        return pd.read_excel(uploaded_file, dtype=str)
    except Exception:
        return pd.DataFrame()


# ---------------------------
# ISIN validation (format + checksum)
# ---------------------------
def isin_format_valid(isin: str) -> bool:
    if not isin or not isinstance(isin, str):
        return False
    return bool(re.match(r"^[A-Z]{2}[A-Z0-9]{9}[0-9]$", isin.strip().upper()))


def isin_checksum_valid(isin: str) -> bool:
    """ISIN checksum (Luhn-like). Returns True for valid ISINs."""
    if not isin_format_valid(isin):
        return False
    s = isin.strip().upper()
    converted = ""
    for ch in s[:-1]:
        if ch.isdigit():
            converted += ch
        else:
            converted += str(ord(ch) - 55)
    digits = converted + s[-1]
    arr = [int(x) for x in digits]
    total = 0
    parity = len(arr) % 2
    for i, d in enumerate(arr):
        if i % 2 == parity:
            d *= 2
            if d > 9:
                d -= 9
        total += d
    return total % 10 == 0


# ---------------------------
# Load TQOB/TQCB board XML caches (for fallback)
# ---------------------------
@st.cache_data(ttl=3600)
def fetch_board_xml(board: str):
    url = (
        "https://iss.moex.com/iss/engines/stock/markets/bonds/boards/"
        f"{board.lower()}/securities.xml?marketprice_board=3&iss.meta=off"
    )
    try:
        r = request_get(url, timeout=20)
        xml_content = r.content.decode("utf-8", errors="ignore")
        xml_content = re.sub(r'\sxmlns="[^"]+"', "", xml_content, count=1)
        root = ET.fromstring(xml_content)
        mapping = {}
        for el in root.iter():
            if el.tag.lower().endswith("row"):
                attrs = {k.upper(): v for k, v in el.attrib.items()}
                isin = attrs.get("ISIN", "").strip().upper()
                secid = attrs.get("SECID", "").strip().upper()
                emitterid = attrs.get("EMITTERID", "").strip()
                if isin:
                    mapping[isin] = {"SECID": secid or None, "EMITTERID": emitterid or None, **attrs}
        return mapping
    except Exception:
        return {}


TQOB_MAP = fetch_board_xml("tqob")
TQCB_MAP = fetch_board_xml("tqcb")

# ---------------------------
# Fetch emitter & secid (with caching)
# ---------------------------
@st.cache_data(ttl=3600)
def fetch_emitter_and_secid(isin: str):
    isin = str(isin).strip().upper()
    if not isin:
        return None, None
    emitter_id = None
    secid = None

    try:
        url = f"https://iss.moex.com/iss/securities/{isin}.json"
        r = request_get(url, timeout=10)
        data = r.json()
        securities = data.get("securities", {})
        cols = securities.get("columns", [])
        rows = securities.get("data", [])
        if rows and cols:
            first = rows[0]
            col_map = {c.upper(): i for i, c in enumerate(cols)}
            if "EMITTER_ID" in col_map:
                emitter_id = first[col_map["EMITTER_ID"]]
            elif "EMITTERID" in col_map:
                emitter_id = first[col_map["EMITTERID"]]
            if "SECID" in col_map:
                secid = first[col_map["SECID"]]
    except Exception:
        pass

    if not secid:
        try:
            url = f"https://iss.moex.com/iss/securities/{isin}.xml?iss.meta=off"
            r = request_get(url, timeout=10)
            xml_content = r.content.decode("utf-8", errors="ignore")
            xml_content = re.sub(r'\sxmlns="[^"]+"', "", xml_content, count=1)
            root = ET.fromstring(xml_content)
            for node in root.iter():
                name_attr = (node.attrib.get("name") or "").upper()
                val_attr = node.attrib.get("value") or ""
                if name_attr == "SECID":
                    secid = val_attr
                elif name_attr in ("EMITTER_ID", "EMITTERID"):
                    emitter_id = val_attr
        except Exception:
            pass

    if not secid:
        mapping = TQOB_MAP.get(isin) or TQCB_MAP.get(isin)
        if mapping:
            secid = mapping.get("SECID")
            if not emitter_id:
                emitter_id = mapping.get("EMITTERID")

    return emitter_id, secid


# ---------------------------
# Core: get bond data per ISIN
# ---------------------------
@st.cache_data(ttl=3600)
def get_bond_data(isin: str):
    isin = str(isin).strip().upper()
    try:
        emitter_id, secid = fetch_emitter_and_secid(isin)
        secname = maturity_date = put_date = call_date = None
        record_date = coupon_date = None
        coupon_currency = None
        coupon_value = None
        coupon_value_rub = None
        coupon_value_prc = None

        if secid:
            try:
                url_info = f"https://iss.moex.com/iss/engines/stock/markets/bonds/securities/{secid}.json"
                r = request_get(url_info, timeout=10)
                data_info = r.json()
                rows_info = data_info.get("securities", {}).get("data", [])
                cols_info = data_info.get("securities", {}).get("columns", [])
                if rows_info and cols_info:
                    info = dict(zip([c.upper() for c in cols_info], rows_info[0]))
                    secname = info.get("SECNAME") or info.get("SEC_NAME") or secname
                    maturity_date = info.get("MATDATE") or maturity_date
                    put_date = info.get("PUTOPTIONDATE") or put_date
                    call_date = info.get("CALLOPTIONDATE") or call_date
            except Exception:
                pass

        if not secname or not maturity_date:
            try:
                url_info_isin = f"https://iss.moex.com/iss/securities/{isin}.json"
                r = request_get(url_info_isin, timeout=10)
                data_info_isin = r.json()
                rows = data_info_isin.get("securities", {}).get("data", [])
                cols = data_info_isin.get("securities", {}).get("columns", [])
                if rows and cols:
                    info = dict(zip([c.upper() for c in cols], rows[0]))
                    secname = secname or info.get("SECNAME") or info.get("SEC_NAME")
                    maturity_date = maturity_date or info.get("MATDATE") or info.get("MATDATE")
                    put_date = put_date or info.get("PUTOPTIONDATE") or info.get("PUT_OPTION_DATE")
                    call_date = call_date or info.get("CALLOPTIONDATE") or info.get("CALL_OPTION_DATE")
            except Exception:
                pass

        coupons_data = None
        columns_coupons = []
        bondization_faceunit = None

        def try_fetch_bondization(identifier: str):
            try:
                url_coupons = (
                    "https://iss.moex.com/iss/statistics/engines/stock/markets/bonds/"
                    f"bondization/{identifier}.json?iss.only=coupons,bondization&iss.meta=off"
                )
                r = request_get(url_coupons, timeout=10)
                data = r.json()
                coupons = data.get("coupons", {}).get("data", [])
                cols = data.get("coupons", {}).get("columns", [])
                bond_rows = data.get("bondization", {}).get("data", [])
                bond_cols = data.get("bondization", {}).get("columns", [])
                faceunit = None
                if bond_rows and bond_cols:
                    bond_info = dict(zip([c.upper() for c in bond_cols], bond_rows[0]))
                    faceunit = bond_info.get("FACEUNIT") or bond_info.get("FACEUNIT_S")
                return coupons, cols, faceunit
            except Exception:
                return None, [], None

        if secid:
            coupons_data, columns_coupons, bondization_faceunit = try_fetch_bondization(secid)

        if isin and (not coupons_data or not columns_coupons):
            coupons_data_fallback, columns_coupons_fallback, bondization_faceunit_fallback = try_fetch_bondization(isin)
            if coupons_data_fallback and columns_coupons_fallback:
                coupons_data = coupons_data_fallback
                columns_coupons = columns_coupons_fallback
            if not bondization_faceunit:
                bondization_faceunit = bondization_faceunit_fallback or bondization_faceunit

        if coupons_data and columns_coupons:
            df_coupons = pd.DataFrame(coupons_data, columns=columns_coupons)
            cols_upper = [c.upper() for c in df_coupons.columns]
            df_coupons.columns = cols_upper
            today = pd.to_datetime(datetime.today().date())
            possible_coupon_date_cols = [c for c in cols_upper if "COUPON" in c and "DATE" in c]
            possible_record_date_cols = [c for c in cols_upper if "RECORD" in c and "DATE" in c]

            def next_future_date(series):
                try:
                    s = pd.to_datetime(series, errors="coerce")
                    s = s[s >= today]
                    if not s.empty:
                        return s.min().strftime("%Y-%m-%d")
                except Exception:
                    pass
                return None

            coupon_found = None
            for col in possible_coupon_date_cols:
                candidate = next_future_date(df_coupons[col])
                if candidate:
                    coupon_found = candidate
                    break
            if not coupon_found:
                all_dates = []
                for col in df_coupons.columns:
                    try:
                        s = pd.to_datetime(df_coupons[col], errors="coerce")
                        s = s[s >= today]
                        if not s.empty:
                            all_dates.append(s.min())
                    except Exception:
                        pass
                if all_dates:
                    coupon_found = min(all_dates).strftime("%Y-%m-%d")
            coupon_date = coupon_found

            record_found = None
            for col in possible_record_date_cols:
                candidate = next_future_date(df_coupons[col])
                if candidate:
                    record_found = candidate
                    break
            record_date = record_found

            if bondization_faceunit:
                coupon_currency = bondization_faceunit
            else:
                faceunit_cols = [c for c in df_coupons.columns if "FACEUNIT" in c or c == "FACEUNIT_S"]
                if faceunit_cols:
                    for c in faceunit_cols:
                        vals = df_coupons[c].dropna().astype(str)
                        if not vals.empty and vals.iloc[0].strip():
                            coupon_currency = vals.iloc[0].strip()
                            break

            val_col = None
            val_rub_col = None
            val_prc_col = None
            for c in df_coupons.columns:
                uc = c.upper()
                if uc in ("VALUE", "VALUE_COUPON", "COUPONVALUE") and not val_col:
                    val_col = c
                if "VALUE_RUB" in uc and not val_rub_col:
                    val_rub_col = c
                if uc in ("VALUEPRC", "VALUE_PRC", "VALUE%") and not val_prc_col:
                    val_prc_col = c
            if not val_col:
                for c in df_coupons.columns:
                    if re.match(r"^VALUE$", c, flags=re.IGNORECASE):
                        val_col = c
                        break
            if not val_rub_col:
                for c in df_coupons.columns:
                    if re.search(r"RUB", c, flags=re.IGNORECASE):
                        if "VALUE" in c.upper() or "RUB" in c.upper():
                            val_rub_col = c
                            break
            if not val_prc_col:
                for c in df_coupons.columns:
                    if re.search(r"PRC|PERC|%|PERCENT", c, flags=re.IGNORECASE):
                        val_prc_col = c
                        break

            chosen_row = None
            if coupon_date:
                for c in possible_coupon_date_cols:
                    try:
                        mask = pd.to_datetime(df_coupons[c], errors="coerce").dt.strftime("%Y-%m-%d") == coupon_date
                        rows = df_coupons[mask]
                        if not rows.empty:
                            chosen_row = rows.iloc[0]
                            break
                    except Exception:
                        pass
            if chosen_row is None:
                for idx in range(len(df_coupons)):
                    row = df_coupons.iloc[idx]
                    has_val = False
                    for colcheck in (val_col, val_rub_col, val_prc_col):
                        try:
                            if colcheck and pd.notnull(row.get(colcheck)):
                                has_val = True
                                break
                        except Exception:
                            pass
                    if has_val:
                        chosen_row = row
                        break

            def norm_str(v):
                if v is None or (isinstance(v, float) and math.isnan(v)):
                    return None
                try:
                    return str(v)
                except Exception:
                    return None

            if chosen_row is not None:
                coupon_value = norm_str(chosen_row.get(val_col)) if val_col else None
                coupon_value_rub = norm_str(chosen_row.get(val_rub_col)) if val_rub_col else None
                coupon_value_prc = norm_str(chosen_row.get(val_prc_col)) if val_prc_col else None

        if (not record_date or not coupon_date or not coupon_currency) and (TQOB_MAP or TQCB_MAP):
            mapping = TQOB_MAP.get(isin) or TQCB_MAP.get(isin)
            if mapping:
                if not record_date:
                    record_date = mapping.get("RECORDDATE") or mapping.get("RECORD_DATE") or mapping.get("RECORD")
                if not coupon_date:
                    coupon_date = mapping.get("COUPONDATE") or mapping.get("COUPON_DATE") or mapping.get("COUPON")
                if not coupon_currency:
                    coupon_currency = mapping.get("FACEUNIT") or mapping.get("FACEUNIT_S") or mapping.get("FACEUNIT")

        def fmt(date):
            if pd.isna(date) or not date:
                return None
            try:
                return pd.to_datetime(date).strftime("%Y-%m-%d")
            except Exception:
                return None

        return {
            "ISIN": isin,
            "–ö–æ–¥ —ç–º–∏—Ç–µ–Ω—Ç–∞": emitter_id or "",
            "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞": secname or "",
            "–î–∞—Ç–∞ –ø–æ–≥–∞—à–µ–Ω–∏—è": fmt(maturity_date),
            "–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Put": fmt(put_date),
            "–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Call": fmt(call_date),
            "–î–∞—Ç–∞ —Ñ–∏–∫—Å–∞—Ü–∏–∏ –∫—É–ø–æ–Ω–∞": fmt(record_date),
            "–î–∞—Ç–∞ –∫—É–ø–æ–Ω–∞": fmt(coupon_date),
            "–í–∞–ª—é—Ç–∞ –∫—É–ø–æ–Ω–∞": coupon_currency or "",
            "–ö—É–ø–æ–Ω –≤ –≤–∞–ª—é—Ç–µ": coupon_value or "",
            "–ö—É–ø–æ–Ω –≤ –†—É–±": coupon_value_rub or "",
            "–ö—É–ø–æ–Ω %": coupon_value_prc or "",
        }
    except Exception:
        return {
            "ISIN": isin,
            "–ö–æ–¥ —ç–º–∏—Ç–µ–Ω—Ç–∞": "",
            "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞": "",
            "–î–∞—Ç–∞ –ø–æ–≥–∞—à–µ–Ω–∏—è": None,
            "–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Put": None,
            "–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Call": None,
            "–î–∞—Ç–∞ —Ñ–∏–∫—Å–∞—Ü–∏–∏ –∫—É–ø–æ–Ω–∞": None,
            "–î–∞—Ç–∞ –∫—É–ø–æ–Ω–∞": None,
            "–í–∞–ª—é—Ç–∞ –∫—É–ø–æ–Ω–∞": "",
            "–ö—É–ø–æ–Ω –≤ –≤–∞–ª—é—Ç–µ": "",
            "–ö—É–ø–æ–Ω –≤ –†—É–±": "",
            "–ö—É–ø–æ–Ω %": "",
        }


# ---------------------------
# Calendar helpers
# ---------------------------
@st.cache_data(ttl=3600)
def get_bond_schedule(isin: str):
    isin = str(isin).strip().upper()
    emitter_id, secid = fetch_emitter_and_secid(isin)
    maturity_date = put_date = call_date = None
    coupon_events = {}
    facevalue = None

    if secid:
        try:
            url_info = f"https://iss.moex.com/iss/engines/stock/markets/bonds/securities/{secid}.json"
            r = request_get(url_info, timeout=10)
            data_info = r.json()
            rows_info = data_info.get("securities", {}).get("data", [])
            cols_info = data_info.get("securities", {}).get("columns", [])
            if rows_info and cols_info:
                info = dict(zip([c.upper() for c in cols_info], rows_info[0]))
                maturity_date = info.get("MATDATE") or maturity_date
                put_date = info.get("PUTOPTIONDATE") or put_date
                call_date = info.get("CALLOPTIONDATE") or call_date
        except Exception:
            pass

    if not maturity_date:
        try:
            url_info_isin = f"https://iss.moex.com/iss/securities/{isin}.json"
            r = request_get(url_info_isin, timeout=10)
            data_info_isin = r.json()
            rows = data_info_isin.get("securities", {}).get("data", [])
            cols = data_info_isin.get("securities", {}).get("columns", [])
            if rows and cols:
                info = dict(zip([c.upper() for c in cols], rows[0]))
                maturity_date = maturity_date or info.get("MATDATE")
                put_date = put_date or info.get("PUTOPTIONDATE") or info.get("PUT_OPTION_DATE")
                call_date = call_date or info.get("CALLOPTIONDATE") or info.get("CALL_OPTION_DATE")
        except Exception:
            pass

    def try_fetch_bondization(identifier: str):
        try:
            url_coupons = (
                "https://iss.moex.com/iss/statistics/engines/stock/markets/bonds/"
                f"bondization/{identifier}.json?iss.only=coupons,bondization&iss.meta=off"
            )
            r = request_get(url_coupons, timeout=10)
            data = r.json()
            coupons = data.get("coupons", {}).get("data", [])
            cols = data.get("coupons", {}).get("columns", [])
            bond_rows = data.get("bondization", {}).get("data", [])
            bond_cols = data.get("bondization", {}).get("columns", [])
            bond_info = None
            if bond_rows and bond_cols:
                bond_info = dict(zip([c.upper() for c in bond_cols], bond_rows[0]))
            return coupons, cols, bond_info
        except Exception:
            return None, [], None

    coupons_data = columns_coupons = None
    bond_info = None
    if secid:
        coupons_data, columns_coupons, bond_info = try_fetch_bondization(secid)

    if isin and (not coupons_data or not columns_coupons):
        coupons_data_fallback, columns_coupons_fallback, bond_info_fallback = try_fetch_bondization(isin)
        if coupons_data_fallback and columns_coupons_fallback:
            coupons_data = coupons_data_fallback
            columns_coupons = columns_coupons_fallback
        if not bond_info:
            bond_info = bond_info_fallback or bond_info

    if bond_info:
        for key, value in bond_info.items():
            if key.startswith("FACEVALUE") and value not in (None, "", "None"):
                facevalue = parse_number(value)
                if facevalue is not None:
                    break

    if coupons_data and columns_coupons:
        df_coupons = pd.DataFrame(coupons_data, columns=columns_coupons)
        df_coupons.columns = [c.upper() for c in df_coupons.columns]
        date_cols = [c for c in df_coupons.columns if "COUPON" in c and "DATE" in c]
        if not date_cols:
            date_cols = [c for c in df_coupons.columns if c.endswith("DATE")]

        val_rub_col = next((c for c in df_coupons.columns if "VALUE_RUB" in c), None)
        val_col = next(
            (c for c in df_coupons.columns if c in ("VALUE", "VALUE_COUPON", "COUPONVALUE")),
            None,
        )
        for _, row in df_coupons.iterrows():
            coupon_date = None
            for col in date_cols:
                dt = pd.to_datetime(row.get(col), errors="coerce")
                if pd.notna(dt):
                    coupon_date = dt.strftime("%Y-%m-%d")
                    break
            if not coupon_date:
                continue
            raw_value = row.get(val_rub_col) if val_rub_col else row.get(val_col)
            coupon_value = parse_number(raw_value)
            if coupon_value is None:
                continue
            coupon_events[coupon_date] = coupon_value

    def fmt(date):
        if pd.isna(date) or not date:
            return None
        try:
            return pd.to_datetime(date).strftime("%Y-%m-%d")
        except Exception:
            return None

    return {
        "ISIN": isin,
        "–ö–æ–¥ —ç–º–∏—Ç–µ–Ω—Ç–∞": emitter_id or "",
        "–î–∞—Ç–∞ –ø–æ–≥–∞—à–µ–Ω–∏—è": fmt(maturity_date),
        "–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Put": fmt(put_date),
        "–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Call": fmt(call_date),
        "–ö—É–ø–æ–Ω—ã": coupon_events,
        "–ù–æ–º–∏–Ω–∞–ª": facevalue,
    }


# ---------------------------
# Parallel fetch with safe progress updates
# ---------------------------
def fetch_isins_parallel(isins, max_workers=10, show_progress=True):
    results = []
    total = len(isins)
    if total == 0:
        return results

    progress_bar = None
    progress_text = None
    if show_progress:
        try:
            progress_bar = st.progress(0)
            progress_text = st.empty()
        except Exception:
            progress_bar = None
            progress_text = None

    completed = 0
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_isin = {executor.submit(get_bond_data, isin): isin for isin in isins}
        for future in as_completed(future_to_isin):
            isin = future_to_isin[future]
            try:
                data = future.result()
            except Exception:
                data = {
                    "ISIN": isin,
                    "–ö–æ–¥ —ç–º–∏—Ç–µ–Ω—Ç–∞": "",
                    "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞": "",
                    "–î–∞—Ç–∞ –ø–æ–≥–∞—à–µ–Ω–∏—è": None,
                    "–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Put": None,
                    "–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Call": None,
                    "–î–∞—Ç–∞ —Ñ–∏–∫—Å–∞—Ü–∏–∏ –∫—É–ø–æ–Ω–∞": None,
                    "–î–∞—Ç–∞ –∫—É–ø–æ–Ω–∞": None,
                    "–í–∞–ª—é—Ç–∞ –∫—É–ø–æ–Ω–∞": "",
                    "–ö—É–ø–æ–Ω –≤ –≤–∞–ª—é—Ç–µ": "",
                    "–ö—É–ø–æ–Ω –≤ –†—É–±": "",
                    "–ö—É–ø–æ–Ω %": "",
                }
            results.append(data)
            completed += 1
            if progress_bar:
                try:
                    progress_bar.progress(completed / total)
                except Exception:
                    pass
            if progress_text:
                try:
                    progress_text.text(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {completed}/{total} ISIN")
                except Exception:
                    pass
    try:
        time.sleep(0.12)
    except Exception:
        pass
    return results


# ---------------------------
# Calendar view
# ---------------------------
if st.session_state["active_view"] == "calendar":
    st.subheader("üìÖ –ö–∞–ª–µ–Ω–¥–∞—Ä—å –≤—ã–ø–ª–∞—Ç")
    st.markdown(
        "–í–≤–µ–¥–∏—Ç–µ —Å–ø–∏—Å–æ–∫ –±—É–º–∞–≥ –∏ –∏—Ö –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ, —á—Ç–æ–±—ã –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –∫–∞–ª–µ–Ω–¥–∞—Ä—å –≤—ã–ø–ª–∞—Ç "
        "(–∫—É–ø–æ–Ω—ã, –ø–æ–≥–∞—à–µ–Ω–∏—è, –æ—Ñ–µ—Ä—Ç—ã) –ø–æ –≤–∞—à–µ–º—É –ø–æ—Ä—Ç—Ñ–µ–ª—é."
    )
    st.markdown("**–†—É—á–Ω–æ–π –≤–≤–æ–¥:** `ISIN | Amount` (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –±—É–º–∞–≥).")
    calendar_input = st.text_area(
        "–í–≤–µ–¥–∏—Ç–µ —Å–ø–∏—Å–æ–∫ –±—É–º–∞–≥",
        height=160,
        placeholder="RU000A0JX0J2 | 100\nRU000A0ZZZY1 | 50",
        key="calendar_manual_input",
    )
    if st.button("–ü–æ—Å—Ç—Ä–æ–∏—Ç—å –∫–∞–ª–µ–Ω–¥–∞—Ä—å", key="build_calendar"):
        raw_lines = [line.strip() for line in calendar_input.splitlines() if line.strip()]
        entries = []
        invalid_isins = []
        for line in raw_lines:
            parts = [p.strip() for p in re.split(r"[,.;|/\t]+", line) if p.strip()]
            if not parts:
                continue
            isin = parts[0].upper()
            amount = parse_number(parts[1]) if len(parts) > 1 else 1.0
            if amount is None or amount <= 0:
                amount = 1.0
            if not isin_format_valid(isin) or not isin_checksum_valid(isin):
                invalid_isins.append(isin)
                continue
            entries.append({"ISIN": isin, "Amount": amount})

        if invalid_isins:
            st.warning(
                "–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ ISIN –ø—Ä–æ–ø—É—â–µ–Ω—ã: "
                f"{', '.join(invalid_isins[:10])}{'...' if len(invalid_isins) > 10 else ''}"
            )
        if not entries:
            st.error("–ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö ISIN –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –∫–∞–ª–µ–Ω–¥–∞—Ä—è.")
        else:
            max_workers = st.sidebar.slider("–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –ø–æ—Ç–æ–∫–æ–≤ (workers)", 2, 40, 10, key="calendar_workers")
            timeline_data = {}
            all_dates = set()
            with st.spinner("–ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –≤—ã–ø–ª–∞—Ç..."):
                with ThreadPoolExecutor(max_workers=max_workers) as executor:
                    future_to_entry = {
                        executor.submit(get_bond_schedule, entry["ISIN"]): entry for entry in entries
                    }
                    for future in as_completed(future_to_entry):
                        entry = future_to_entry[future]
                        isin = entry["ISIN"]
                        amount = entry["Amount"]
                        try:
                            schedule = future.result()
                        except Exception:
                            schedule = {}
                        row = {}
                        today = datetime.today().date()
                        for date, value in schedule.get("–ö—É–ø–æ–Ω—ã", {}).items():
                            scaled = value * amount if value is not None else None
                            if scaled is None:
                                continue
                            try:
                                coupon_date = pd.to_datetime(date).date()
                            except Exception:
                                continue
                            if coupon_date >= today:
                                row[date] = row.get(date, 0) + scaled
                                all_dates.add(date)
                        facevalue = schedule.get("–ù–æ–º–∏–Ω–∞–ª")
                        event_date = schedule.get("–î–∞—Ç–∞ –ø–æ–≥–∞—à–µ–Ω–∏—è")
                        if event_date and facevalue is not None:
                            try:
                                maturity_date = pd.to_datetime(event_date).date()
                            except Exception:
                                maturity_date = None
                            if maturity_date and maturity_date >= today:
                                row[event_date] = row.get(event_date, 0) + facevalue * amount
                                all_dates.add(event_date)
                        timeline_data[isin] = row

            sorted_dates = sorted(all_dates)
            df_timeline = pd.DataFrame(index=[e["ISIN"] for e in entries], columns=sorted_dates, dtype=float)
            for isin, row in timeline_data.items():
                for date, value in row.items():
                    df_timeline.loc[isin, date] = value
            st.dataframe(df_timeline, use_container_width=True)
    st.stop()

# ---------------------------
# REPO duration settings
# ---------------------------
st.subheader("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –†–ï–ü–û")
if "overnight" not in st.session_state:
    st.session_state["overnight"] = False
if "extra_days" not in st.session_state:
    st.session_state["extra_days"] = 2

if st.button("üîÑ –û—á–∏—Å—Ç–∏—Ç—å —Ñ–æ—Ä–º—É"):
    st.session_state["overnight"] = False
    st.session_state["extra_days"] = 2
    st.session_state["results"] = None
    st.session_state["file_loaded"] = False
    st.session_state["last_file_name"] = None
    trigger_rerun()

overnight = st.checkbox("Overnight –†–ï–ü–û", key="overnight")
extra_days_input = st.number_input(
    "–î–Ω–µ–π –†–ï–ü–û:",
    min_value=2,
    max_value=366,
    step=1,
    disabled=st.session_state["overnight"],
    key="extra_days",
)
if st.session_state["overnight"]:
    st.markdown(
        "<span style='color:gray'>–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–Ω–∏ –æ—Ç–∫–ª—é—á–µ–Ω—ã –ø—Ä–∏ –≤–∫–ª—é—á–µ–Ω–Ω–æ–º Overnight</span>",
        unsafe_allow_html=True,
    )
days_threshold = 2 if st.session_state["overnight"] else 1 + st.session_state["extra_days"]
st.write(f"–¢–µ–∫—É—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≥—Ä–∞–Ω–∏—Ü—ã –≤—ã–ø–ª–∞—Ç: {days_threshold} –¥–Ω.")

# ---------------------------
# UI: input tabs
# ---------------------------
st.subheader("üì§ –ó–∞–≥—Ä—É–∑–∫–∞ –∏–ª–∏ –≤–≤–æ–¥ ISIN")
tab1, tab2 = st.tabs(["üìÅ –ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª", "‚úçÔ∏è –í–≤–µ—Å—Ç–∏ –≤—Ä—É—á–Ω—É—é"])

with tab1:
    uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ Excel –∏–ª–∏ CSV —Å –∫–æ–ª–æ–Ω–∫–æ–π ISIN", type=["xlsx", "xls", "csv"])
    st.write("–ü—Ä–∏–º–µ—Ä —à–∞–±–ª–æ–Ω–∞ (—Å–∫–∞—á–∞–π—Ç–µ –∏ –∑–∞–ø–æ–ª–Ω–∏—Ç–µ –∫–æ–ª–æ–Ω–∫—É ISIN):")
    sample_csv = "ISIN\nRU000A0JX0J2\nRU000A0ZZZY1\n"
    st.download_button("–°–∫–∞—á–∞—Ç—å —à–∞–±–ª–æ–Ω CSV", data=sample_csv, file_name="template_isin.csv", mime="text/csv")

with tab2:
    isin_input = st.text_area("–í–≤–µ–¥–∏—Ç–µ –∏–ª–∏ –≤—Å—Ç–∞–≤—å—Ç–µ ISIN (—á–µ—Ä–µ–∑ Ctrl+V, –ø—Ä–æ–±–µ–ª –∏–ª–∏ –∑–∞–ø—è—Ç—É—é)", height=150)
    if st.button("üîç –ü–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –ø–æ –≤–≤–µ–¥—ë–Ω–Ω—ã–º ISIN"):
        raw_text = isin_input.strip()
        if raw_text:
            isins = re.split(r"[\s,;]+", raw_text)
            isins = [i.strip().upper() for i in isins if i.strip()]
            invalid_format = [i for i in isins if not isin_format_valid(i)]
            invalid_checksum = [i for i in isins if isin_format_valid(i) and not isin_checksum_valid(i)]
            if invalid_format:
                st.warning(
                    f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –ø–æ —Ñ–æ—Ä–º–∞—Ç—É ISIN –±—É–¥—É—Ç –ø—Ä–æ–ø—É—â–µ–Ω—ã: {', '.join(invalid_format[:10])}"
                    f"{'...' if len(invalid_format) > 10 else ''}"
                )
            if invalid_checksum:
                st.info(
                    f"ISIN —Å –Ω–µ–≤–µ—Ä–Ω–æ–π –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω–æ–π —Å—É–º–º–æ–π (–±—É–¥—É—Ç –ø—Ä–æ–ø—É—â–µ–Ω—ã): {', '.join(invalid_checksum[:10])}"
                    f"{'...' if len(invalid_checksum) > 10 else ''}"
                )
            isins = [i for i in isins if isin_format_valid(i) and isin_checksum_valid(i)]
            if not isins:
                st.error("–ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö ISIN –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.")
            else:
                max_workers = st.sidebar.slider("–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –ø–æ—Ç–æ–∫–æ–≤ (workers)", 2, 40, 10)
                with st.spinner("–ó–∞–ø—Ä–æ—Å –¥–∞–Ω–Ω—ã—Ö..."):
                    results = fetch_isins_parallel(isins, max_workers=max_workers, show_progress=True)
                st.session_state["results"] = pd.DataFrame(results)
                st.success("‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω—ã!")

# ---------------------------
# File upload handling
# ---------------------------
if uploaded_file:
    if not st.session_state["file_loaded"] or uploaded_file.name != st.session_state["last_file_name"]:
        st.session_state["file_loaded"] = True
        st.session_state["last_file_name"] = uploaded_file.name

        df = safe_read_filelike(uploaded_file)
        if df.empty:
            st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª –∏–ª–∏ —Ñ–∞–π–ª –ø—É—Å—Ç.")
            st.stop()
        df.columns = [c.strip().upper() for c in df.columns]

        if "ISIN" not in df.columns:
            candidates = []
            for c in df.columns:
                try:
                    if df[c].dropna().astype(str).str.match(r"^[A-Z]{2}[A-Z0-9]{9}[0-9]$").any():
                        candidates.append(c)
                except Exception:
                    continue
            if len(candidates) == 1:
                df.rename(columns={candidates[0]: "ISIN"}, inplace=True)
                st.info(f"–ê–≤—Ç–æ-–¥–µ—Ç–µ–∫—Ç: –∫–æ–ª–æ–Ω–∫–∞ '{candidates[0]}' –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ –∫–∞–∫ ISIN")
            else:
                st.error("‚ùå –í —Ñ–∞–π–ª–µ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –∫–æ–ª–æ–Ω–∫–∞ 'ISIN' –∏–ª–∏ –æ–¥–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ —Å ISIN-–ø–æ–¥–æ–±–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏.")
                st.stop()

        isins = df["ISIN"].dropna().unique().tolist()
        isins = [str(x).strip().upper() for x in isins if str(x).strip()]
        invalid_fmt = [i for i in isins if not isin_format_valid(i)]
        invalid_chk = [i for i in isins if isin_format_valid(i) and not isin_checksum_valid(i)]
        if invalid_fmt:
            st.warning(
                f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –ø–æ —Ñ–æ—Ä–º–∞—Ç—É ISIN –ø—Ä–æ–ø—É—â–µ–Ω—ã: {', '.join(invalid_fmt[:10])}"
                f"{'...' if len(invalid_fmt) > 10 else ''}"
            )
        if invalid_chk:
            st.info(
                f"ISIN —Å –Ω–µ–≤–µ—Ä–Ω–æ–π –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω–æ–π —Å—É–º–º–æ–π –ø—Ä–æ–ø—É—â–µ–Ω—ã: {', '.join(invalid_chk[:10])}"
                f"{'...' if len(invalid_chk) > 10 else ''}"
            )
        isins = [i for i in isins if isin_format_valid(i) and isin_checksum_valid(i)]

        st.write(f"–ù–∞–π–¥–µ–Ω–æ {len(isins)} –≤–∞–ª–∏–¥–Ω—ã—Ö —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö ISIN –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.")
        if isins:
            max_workers = st.sidebar.slider("–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –ø–æ—Ç–æ–∫–æ–≤ (workers)", 2, 40, 10)
            with st.spinner("–ó–∞–ø—Ä–æ—Å –¥–∞–Ω–Ω—ã—Ö –ø–æ —Ñ–∞–π–ª—É..."):
                results = fetch_isins_parallel(isins, max_workers=max_workers, show_progress=True)
            st.session_state["results"] = pd.DataFrame(results)
            st.success("‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω—ã –∏–∑ —Ñ–∞–π–ª–∞!")

# ---------------------------
# Load emitter reference (optional)
# ---------------------------
@st.cache_data(ttl=3600)
def fetch_emitter_names():
    url = "https://raw.githubusercontent.com/mainarkler/Bond_date/refs/heads/main/Pifagr_name_with_emitter.csv"
    try:
        df_emitters = pd.read_csv(url, dtype=str)
        df_emitters.columns = [c.strip() for c in df_emitters.columns]
        return df_emitters
    except Exception:
        return pd.DataFrame(columns=["Issuer", "EMITTER_ID"])


df_emitters = fetch_emitter_names()

# ---------------------------
# Styling helper
# ---------------------------
def style_df(row):
    if pd.isna(row.get("–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞")) or row.get("–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞") in [None, "", "None"]:
        return ["background-color: DimGray; color: white"] * len(row)
    today = datetime.today().date()
    danger_threshold = today + timedelta(days=days_threshold)
    key_dates = ["–î–∞—Ç–∞ –ø–æ–≥–∞—à–µ–Ω–∏—è", "–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Put", "–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Call", "–î–∞—Ç–∞ —Ñ–∏–∫—Å–∞—Ü–∏–∏ –∫—É–ø–æ–Ω–∞", "–î–∞—Ç–∞ –∫—É–ø–æ–Ω–∞"]
    colors = ["" for _ in row]
    for i, col in enumerate(row.index):
        if col in key_dates and pd.notnull(row[col]):
            try:
                d = pd.to_datetime(row[col]).date()
                if d <= danger_threshold:
                    colors[i] = "background-color: Chocolate"
            except Exception:
                pass
    if any(c == "background-color: Chocolate" for c in colors):
        colors = ["background-color: SandyBrown" if c == "" else c for c in colors]
    return colors

# ---------------------------
# Show results (table + export) with filter for orange-highlighted rows
# ---------------------------
if st.session_state["results"] is not None:
    df_res = st.session_state["results"].copy()

    if "–ö–æ–¥ —ç–º–∏—Ç–µ–Ω—Ç–∞" in df_res.columns and not df_emitters.empty:
        try:
            df_res = df_res.merge(df_emitters, how="left", left_on="–ö–æ–¥ —ç–º–∏—Ç–µ–Ω—Ç–∞", right_on="EMITTER_ID")
            df_res["–≠–º–∏—Ç–µ–Ω—Ç"] = df_res.get("Issuer")
            df_res.drop(columns=["Issuer", "EMITTER_ID"], inplace=True, errors="ignore")
            cols = df_res.columns.tolist()
            if "–≠–º–∏—Ç–µ–Ω—Ç" in cols and "–ö–æ–¥ —ç–º–∏—Ç–µ–Ω—Ç–∞" in cols:
                cols.remove("–≠–º–∏—Ç–µ–Ω—Ç")
                idx = cols.index("–ö–æ–¥ —ç–º–∏—Ç–µ–Ω—Ç–∞")
                cols.insert(idx + 1, "–≠–º–∏—Ç–µ–Ω—Ç")
                df_res = df_res[cols]
            st.session_state["results"] = df_res
        except Exception:
            pass
    else:
        st.warning("‚ö†Ô∏è –í –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ '–ö–æ–¥ —ç–º–∏—Ç–µ–Ω—Ç–∞' ‚Äî –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å–æ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–æ–º –ø—Ä–æ–ø—É—â–µ–Ω–æ.")

    st.markdown(f"**–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π:** {len(df_res)}")

    today = datetime.today().date()
    danger_threshold = today + timedelta(days=days_threshold)
    key_dates = ["–î–∞—Ç–∞ –ø–æ–≥–∞—à–µ–Ω–∏—è", "–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Put", "–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Call", "–î–∞—Ç–∞ —Ñ–∏–∫—Å–∞—Ü–∏–∏ –∫—É–ø–æ–Ω–∞", "–î–∞—Ç–∞ –∫—É–ø–æ–Ω–∞"]

    mask_any = pd.Series(False, index=df_res.index)
    for col in key_dates:
        if col in df_res.columns:
            try:
                s = pd.to_datetime(df_res[col], errors="coerce").dt.date
                mask_any = mask_any | (s <= danger_threshold)
            except Exception:
                pass

    only_orange = st.checkbox("–ü–æ–∫–∞–∑–∞—Ç—å –±—É–º–∞–≥–∏ —Å –æ—Ç—Å–µ—á–∫–æ–π –≤ –ø–µ—Ä–∏–æ–¥–µ", value=False)
    if only_orange:
        df_show = df_res[mask_any].copy()
        st.markdown(f"**–ü–æ–∫–∞–∑–∞–Ω–æ –∑–∞–ø–∏—Å–µ–π —Å –æ—Ç—Å–µ—á–∫–æ–π:** {len(df_show)}")
        if df_show.empty:
            st.info("–ù–µ—Ç –±—É–º–∞–≥, –ø–æ–ø–∞–¥–∞—é—â–∏—Ö –ø–æ–¥ –∫—Ä–∏—Ç–µ—Ä–∏–π (–æ—Ç—Å–µ—á–∫–∏).")
    else:
        df_show = df_res

    st.dataframe(df_show.style.apply(style_df, axis=1), use_container_width=True)

    def to_excel_bytes(df: pd.DataFrame):
        output = BytesIO()
        with pd.ExcelWriter(output, engine="openpyxl") as writer:
            df.to_excel(writer, index=False, sheet_name="–î–∞–Ω–Ω—ã–µ")
        return output.getvalue()

    def to_csv_bytes(df: pd.DataFrame):
        return df.to_csv(index=False).encode("utf-8-sig")

    st.download_button(
        label="üíæ –°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç (Excel)",
        data=to_excel_bytes(df_show),
        file_name="bond_data.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
    )
    st.download_button(
        label="üíæ –°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç (CSV)",
        data=to_csv_bytes(df_show),
        file_name="bond_data.csv",
        mime="text/csv",
    )
else:
    st.info("üëÜ –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –∏–ª–∏ –≤–≤–µ–¥–∏—Ç–µ ISIN-—ã –≤—Ä—É—á–Ω—É—é.")
