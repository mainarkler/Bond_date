import streamlit as st
import pandas as pd
import requests
import xml.etree.ElementTree as ET
from datetime import datetime, timedelta
from io import BytesIO, StringIO
import os
import csv
import re
from concurrent.futures import ThreadPoolExecutor, as_completed

# === –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã ===
st.set_page_config(page_title="–†–ï–ü–û –ø—Ä–µ—Ç—Ä–µ–π–¥", page_icon="üìà", layout="wide")
st.title("üìà –†–ï–ü–û –ø—Ä–µ—Ç—Ä–µ–π–¥")

# === Session state ===
if "results" not in st.session_state:
    st.session_state["results"] = None
if "file_loaded" not in st.session_state:
    st.session_state["file_loaded"] = False
if "last_file_name" not in st.session_state:
    st.session_state["last_file_name"] = None

# === –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –†–ï–ü–û ===
st.subheader("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –†–ï–ü–û")
if "overnight" not in st.session_state:
    st.session_state["overnight"] = False
if "extra_days" not in st.session_state:
    st.session_state["extra_days"] = 2

if st.button("üîÑ –û—á–∏—Å—Ç–∏—Ç—å —Ñ–æ—Ä–º—É"):
    st.session_state["overnight"] = False
    st.session_state["extra_days"] = 2
    st.session_state["results"] = None
    st.session_state["file_loaded"] = False
    st.session_state["last_file_name"] = None
    st.rerun()

overnight = st.checkbox("Overnight –†–ï–ü–û", key="overnight")
extra_days_input = st.number_input(
    "–î–Ω–µ–π –†–ï–ü–û:",
    min_value=2,
    max_value=366,
    step=1,
    disabled=st.session_state["overnight"],
    key="extra_days",
)
if st.session_state["overnight"]:
    st.markdown("<span style='color:gray'>–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–Ω–∏ –æ—Ç–∫–ª—é—á–µ–Ω—ã –ø—Ä–∏ –≤–∫–ª—é—á–µ–Ω–Ω–æ–º Overnight</span>", unsafe_allow_html=True)
days_threshold = 2 if st.session_state["overnight"] else 1 + st.session_state["extra_days"]
st.write(f"–¢–µ–∫—É—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≥—Ä–∞–Ω–∏—Ü—ã –≤—ã–ø–ª–∞—Ç: {days_threshold} –¥–Ω.")

# === –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ —á—Ç–µ–Ω–∏–µ CSV ===
def safe_read_csv(path):
    if not os.path.exists(path):
        st.warning(f"‚ö†Ô∏è –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {path}")
        return pd.DataFrame()
    try:
        with open(path, "r", encoding="utf-8-sig") as f:
            content = f.read()
        content = content.replace('\r\n', '\n').strip()
        sample = content[:2048]
        try:
            dialect = csv.Sniffer().sniff(sample, delimiters=[",", ";", "\t"])
            sep = dialect.delimiter
        except Exception:
            sep = ","
        df = pd.read_csv(StringIO(content), sep=sep, dtype=str)
        df.columns = [c.strip().upper() for c in df.columns]
        return df
    except Exception as e:
        st.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ {os.path.basename(path)}: {e}")
        return pd.DataFrame()

# === MOEX API session ===
session = requests.Session()
session.headers.update({"User-Agent": "python-requests/iss-moex-script"})

# === –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ XML TQOB –∏ TQCB ===
@st.cache_data(ttl=3600)
def fetch_board_xml(board: str):
    url = f"https://iss.moex.com/iss/engines/stock/markets/bonds/boards/{board.lower()}/securities.xml?marketprice_board=3&iss.meta=off"
    try:
        r = session.get(url, timeout=20)
        r.raise_for_status()
        xml_content = r.content.decode("utf-8", errors="ignore")
        xml_content = re.sub(r'\sxmlns="[^"]+"', "", xml_content, count=1)
        root = ET.fromstring(xml_content)
        mapping = {}
        for el in root.iter():
            if el.tag.lower().endswith("row"):
                attrs = {k.upper(): v for k, v in el.attrib.items()}
                isin = attrs.get("ISIN", "").strip().upper()
                secid = attrs.get("SECID", "").strip().upper()
                emitterid = attrs.get("EMITTERID", "").strip()
                if isin:
                    mapping[isin] = {"SECID": secid or None, "EMITTERID": emitterid or None, **attrs}
        return mapping
    except Exception as e:
        st.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å {board}: {e}")
        return {}

TQOB_MAP = fetch_board_xml("tqob")
TQCB_MAP = fetch_board_xml("tqcb")

# === –§—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞ —ç–º–∏—Ç–µ–Ω—Ç–∞ –∏ SECID ===
@st.cache_data(ttl=3600)
def fetch_emitter_and_secid(isin: str):
    isin = str(isin).strip().upper()
    if not isin:
        return None, None
    emitter_id = None
    secid = None

    # 1) JSON
    try:
        url = f"https://iss.moex.com/iss/securities/{isin}.json"
        r = session.get(url, timeout=10)
        r.raise_for_status()
        data = r.json()
        securities = data.get("securities", {})
        cols = securities.get("columns", [])
        rows = securities.get("data", [])
        if rows:
            first = rows[0]
            col_map = {c.upper(): i for i, c in enumerate(cols)}
            emitter_id = first[col_map.get("EMITTER_ID", -1)] if "EMITTER_ID" in col_map else None
            secid = first[col_map.get("SECID", -1)] if "SECID" in col_map else None
    except Exception:
        pass

    # 2) XML
    if not secid:
        try:
            url = f"https://iss.moex.com/iss/securities/{isin}.xml?iss.meta=off"
            r = session.get(url, timeout=10)
            r.raise_for_status()
            xml_content = r.content.decode("utf-8", errors="ignore")
            xml_content = re.sub(r'\sxmlns="[^"]+"', "", xml_content, count=1)
            root = ET.fromstring(xml_content)
            for node in root.iter():
                name_attr = (node.attrib.get("name") or "").upper()
                val_attr = node.attrib.get("value") or ""
                if name_attr == "SECID":
                    secid = val_attr
                elif name_attr == "EMITTER_ID":
                    emitter_id = val_attr
        except Exception:
            pass

    # 3) XML-–±–æ—Ä–¥—ã
    if not secid:
        m = TQOB_MAP.get(isin) or TQCB_MAP.get(isin)
        if m:
            secid = m.get("SECID")
            if not emitter_id:
                emitter_id = m.get("EMITTERID")

    return emitter_id, secid

# === –§—É–Ω–∫—Ü–∏—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –ø–æ ISIN ===
@st.cache_data(ttl=3600)
def get_bond_data(isin):
    try:
        emitter_id, secid = fetch_emitter_and_secid(isin)
        secname = maturity_date = put_date = call_date = None
        record_date = coupon_date = None

        # --- –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –±—É–º–∞–≥–µ –ø–æ SECID ---
        if secid:
            try:
                url_info = f"https://iss.moex.com/iss/engines/stock/markets/bonds/securities/{secid}.json"
                r = session.get(url_info, timeout=10)
                if r.status_code == 200:
                    data_info = r.json()
                    rows_info = data_info.get("securities", {}).get("data", [])
                    cols_info = data_info.get("securities", {}).get("columns", [])
                    if rows_info:
                        info = dict(zip(cols_info, rows_info[0]))
                        secname = info.get("SECNAME") or info.get("SEC_NAME")
                        maturity_date = info.get("MATDATE")
                        put_date = info.get("PUTOPTIONDATE")
                        call_date = info.get("CALLOPTIONDATE")
            except Exception:
                pass

        # --- –ö—É–ø–æ–Ω—ã ---
        if secid:
            try:
                url_coupons = f"https://iss.moex.com/iss/statistics/engines/stock/markets/bonds/bondization/{secid}.json?iss.only=coupons&iss.meta=off"
                r = session.get(url_coupons, timeout=10)
                r.raise_for_status()
                data_coupons = r.json()
                coupons = data_coupons.get("coupons", {}).get("data", [])
                columns_coupons = data_coupons.get("coupons", {}).get("columns", [])
                if coupons:
                    df_coupons = pd.DataFrame(coupons, columns=columns_coupons)
                    today = pd.to_datetime(datetime.today().date())

                    def next_date(col):
                        if col in df_coupons:
                            future = pd.to_datetime(df_coupons[col], errors="coerce")
                            future = future[future >= today]
                            return future.min() if not future.empty else None
                        return None

                    record_date = next_date("recorddate")
                    coupon_date = next_date("coupondate")
            except Exception:
                pass

        def fmt(date):
            if pd.isna(date) or not date:
                return None
            try:
                return pd.to_datetime(date).strftime("%Y-%m-%d")
            except Exception:
                return None

        return {
            "ISIN": isin,
            "–ö–æ–¥ —ç–º–∏—Ç–µ–Ω—Ç–∞": emitter_id or "",
            "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞": secname or "",
            "–î–∞—Ç–∞ –ø–æ–≥–∞—à–µ–Ω–∏—è": fmt(maturity_date),
            "–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Put": fmt(put_date),
            "–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Call": fmt(call_date),
            "–î–∞—Ç–∞ —Ñ–∏–∫—Å–∞—Ü–∏–∏ –∫—É–ø–æ–Ω–∞": fmt(record_date),
            "–î–∞—Ç–∞ –∫—É–ø–æ–Ω–∞": fmt(coupon_date),
        }

    except Exception as e:
        st.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {isin}: {e}")
        return {
            "ISIN": isin,
            "–ö–æ–¥ —ç–º–∏—Ç–µ–Ω—Ç–∞": "",
            "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞": "",
            "–î–∞—Ç–∞ –ø–æ–≥–∞—à–µ–Ω–∏—è": None,
            "–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Put": None,
            "–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Call": None,
            "–î–∞—Ç–∞ —Ñ–∏–∫—Å–∞—Ü–∏–∏ –∫—É–ø–æ–Ω–∞": None,
            "–î–∞—Ç–∞ –∫—É–ø–æ–Ω–∞": None,
        }

# === –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ ===
def fetch_isins_parallel(isins):
    results = []
    with ThreadPoolExecutor(max_workers=10) as executor:
        future_to_isin = {executor.submit(get_bond_data, isin): isin for isin in isins}
        for future in as_completed(future_to_isin):
            data = future.result()
            if data:
                results.append(data)
    return results

# === –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –≤–≤–æ–¥–∞ ===
st.subheader("üì§ –ó–∞–≥—Ä—É–∑–∫–∞ –∏–ª–∏ –≤–≤–æ–¥ ISIN")
tab1, tab2 = st.tabs(["üìÅ –ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª", "‚úçÔ∏è –í–≤–µ—Å—Ç–∏ –≤—Ä—É—á–Ω—É—é"])

with tab1:
    uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ Excel –∏–ª–∏ CSV —Å –∫–æ–ª–æ–Ω–∫–æ–π ISIN", type=["xlsx", "xls", "csv"])

with tab2:
    isin_input = st.text_area("–í–≤–µ–¥–∏—Ç–µ –∏–ª–∏ –≤—Å—Ç–∞–≤—å—Ç–µ ISIN (—á–µ—Ä–µ–∑ Ctrl+V, –ø—Ä–æ–±–µ–ª –∏–ª–∏ –∑–∞–ø—è—Ç—É—é)", height=150)
    if st.button("üîç –ü–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –ø–æ –≤–≤–µ–¥—ë–Ω–Ω—ã–º ISIN"):
        raw_text = isin_input.strip()
        if raw_text:
            isins = re.split(r"[\s,;]+", raw_text)
            isins = [i.strip().upper() for i in isins if i.strip()]
            results = fetch_isins_parallel(isins)
            st.session_state["results"] = pd.DataFrame(results)
            st.success("‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω—ã!")

# === –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞ ===
if uploaded_file:
    if not st.session_state["file_loaded"] or uploaded_file.name != st.session_state["last_file_name"]:
        st.session_state["file_loaded"] = True
        st.session_state["last_file_name"] = uploaded_file.name
        try:
            if uploaded_file.name.lower().endswith(".csv"):
                df = pd.read_csv(uploaded_file, dtype=str)
            else:
                df = pd.read_excel(uploaded_file, dtype=str)
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞: {e}")
            st.stop()

        df.columns = [c.strip().upper() for c in df.columns]
        if "ISIN" not in df.columns:
            st.error("‚ùå –í —Ñ–∞–π–ª–µ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –∫–æ–ª–æ–Ω–∫–∞ 'ISIN'.")
            st.stop()
        isins = df["ISIN"].dropna().unique().tolist()
        isins = [str(x).strip().upper() for x in isins if str(x).strip()]
        results = fetch_isins_parallel(isins)
        st.session_state["results"] = pd.DataFrame(results)
        st.success("‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω—ã –∏–∑ —Ñ–∞–π–ª–∞!")

# === –ü–æ–¥–≥—Ä—É–∑–∫–∞ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∞ —ç–º–∏—Ç–µ–Ω—Ç–æ–≤ ===
@st.cache_data(ttl=3600)
def fetch_emitter_names():
    url = "https://raw.githubusercontent.com/mainarkler/Bond_date/refs/heads/main/Pifagr_name_with_emitter.csv"
    try:
        df_emitters = pd.read_csv(url, dtype=str)
        df_emitters.columns = [c.strip() for c in df_emitters.columns]
        return df_emitters
    except Exception as e:
        st.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫ —ç–º–∏—Ç–µ–Ω—Ç–æ–≤: {e}")
        return pd.DataFrame(columns=["Issuer", "EMITTER_ID"])

df_emitters = fetch_emitter_names()

# === –°—Ç–∏–ª–∏–∑–∞—Ü–∏—è —Ç–∞–±–ª–∏—Ü—ã ===
def style_df(row):
    if pd.isna(row.get("–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞")) or row.get("–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞") in [None, "None", ""]:
        return ["background-color: DimGray; color: white"] * len(row)
    today = datetime.today().date()
    danger_threshold = today + timedelta(days=days_threshold)
    key_dates = ["–î–∞—Ç–∞ –ø–æ–≥–∞—à–µ–Ω–∏—è", "–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Put", "–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Call", "–î–∞—Ç–∞ —Ñ–∏–∫—Å–∞—Ü–∏–∏ –∫—É–ø–æ–Ω–∞", "–î–∞—Ç–∞ –∫—É–ø–æ–Ω–∞"]
    colors = ["" for _ in row]
    for i, col in enumerate(row.index):
        if col in key_dates and pd.notnull(row[col]):
            try:
                d = pd.to_datetime(row[col]).date()
                if d <= danger_threshold:
                    colors[i] = "background-color: Chocolate"
            except:
                pass
    if any(c == "background-color: Chocolate" for c in colors):
        colors = ["background-color: SandyBrown" if c == "" else c for c in colors]
    return colors

# === –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ===
if st.session_state["results"] is not None:
    df_res = st.session_state["results"].copy()

    if "–ö–æ–¥ —ç–º–∏—Ç–µ–Ω—Ç–∞" in df_res.columns and not df_emitters.empty:
        df_res = df_res.merge(df_emitters, how="left", left_on="–ö–æ–¥ —ç–º–∏—Ç–µ–Ω—Ç–∞", right_on="EMITTER_ID")
        df_res["–≠–º–∏—Ç–µ–Ω—Ç"] = df_res["Issuer"]
        df_res.drop(columns=["Issuer", "EMITTER_ID"], inplace=True, errors="ignore")

        cols = df_res.columns.tolist()
        if "–≠–º–∏—Ç–µ–Ω—Ç" in cols and "–ö–æ–¥ —ç–º–∏—Ç–µ–Ω—Ç–∞" in cols:
            cols.remove("–≠–º–∏—Ç–µ–Ω—Ç")
            idx = cols.index("–ö–æ–¥ —ç–º–∏—Ç–µ–Ω—Ç–∞")
            cols.insert(idx + 1, "–≠–º–∏—Ç–µ–Ω—Ç")
            df_res = df_res[cols]

        st.session_state["results"] = df_res
    else:
        st.warning("‚ö†Ô∏è –í –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ '–ö–æ–¥ —ç–º–∏—Ç–µ–Ω—Ç–∞' ‚Äî –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å–æ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–æ–º –ø—Ä–æ–ø—É—â–µ–Ω–æ.")

    st.dataframe(df_res.style.apply(style_df, axis=1), use_container_width=True)

    def to_excel(df):
        output = BytesIO()
        with pd.ExcelWriter(output, engine="openpyxl") as writer:
            df.to_excel(writer, index=False, sheet_name="–î–∞–Ω–Ω—ã–µ")
        return output.getvalue()

    st.download_button(
        label="üíæ –°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç (Excel)",
        data=to_excel(df_res),
        file_name="bond_data.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
    )
else:
    st.info("üëÜ –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –∏–ª–∏ –≤–≤–µ–¥–∏—Ç–µ ISIN-—ã –≤—Ä—É—á–Ω—É—é.")
