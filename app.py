import streamlit as st
import pandas as pd
import requests
import xml.etree.ElementTree as ET
from datetime import datetime, timedelta
from io import BytesIO, StringIO
import os
import csv
import re
from concurrent.futures import ThreadPoolExecutor, as_completed

# === –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã ===
st.set_page_config(page_title="–†–ï–ü–û –ø—Ä–µ—Ç—Ä–µ–π–¥", page_icon="üìà", layout="wide")
st.title("üìà –†–ï–ü–û –ø—Ä–µ—Ç—Ä–µ–π–¥")

# === Session state ===
if "results" not in st.session_state:
    st.session_state["results"] = None
if "file_loaded" not in st.session_state:
    st.session_state["file_loaded"] = False
if "last_file_name" not in st.session_state:
    st.session_state["last_file_name"] = None

# === –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –†–ï–ü–û ===
st.subheader("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –†–ï–ü–û")
if "overnight" not in st.session_state:
    st.session_state["overnight"] = False
if "extra_days" not in st.session_state:
    st.session_state["extra_days"] = 2

if st.button("üîÑ –û—á–∏—Å—Ç–∏—Ç—å —Ñ–æ—Ä–º—É"):
    st.session_state["overnight"] = False
    st.session_state["extra_days"] = 2
    st.session_state["results"] = None
    st.session_state["file_loaded"] = False
    st.session_state["last_file_name"] = None
    st.rerun()

overnight = st.checkbox("Overnight –†–ï–ü–û", key="overnight")
extra_days_input = st.number_input(
    "–î–Ω–µ–π –†–ï–ü–û:",
    min_value=2,
    max_value=366,
    step=1,
    disabled=st.session_state["overnight"],
    key="extra_days",
)
if st.session_state["overnight"]:
    st.markdown("<span style='color:gray'>–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–Ω–∏ –æ—Ç–∫–ª—é—á–µ–Ω—ã –ø—Ä–∏ –≤–∫–ª—é—á–µ–Ω–Ω–æ–º Overnight</span>", unsafe_allow_html=True)
days_threshold = 2 if st.session_state["overnight"] else 1 + st.session_state["extra_days"]
st.write(f"–¢–µ–∫—É—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≥—Ä–∞–Ω–∏—Ü—ã –≤—ã–ø–ª–∞—Ç: {days_threshold} –¥–Ω.")

# === –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ —á—Ç–µ–Ω–∏–µ CSV ===
def safe_read_csv(path):
    if not os.path.exists(path):
        st.warning(f"‚ö†Ô∏è –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {path}")
        return pd.DataFrame()
    try:
        with open(path, "r", encoding="utf-8-sig") as f:
            content = f.read()
        # —É–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –∫–∞–≤—ã—á–∫–∏, –Ω–æ –∞–∫–∫—É—Ä–∞—Ç–Ω–æ ‚Äî –Ω–µ –ª–æ–º–∞–µ–º CSV
        content = content.replace('\r\n', '\n').strip()
        sample = content[:2048]
        try:
            dialect = csv.Sniffer().sniff(sample, delimiters=[",", ";", "\t"])
            sep = dialect.delimiter
        except Exception:
            sep = ","
        df = pd.read_csv(StringIO(content), sep=sep, dtype=str)
        df.columns = [c.strip().upper() for c in df.columns]
        return df
    except Exception as e:
        st.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ {os.path.basename(path)}: {e}")
        return pd.DataFrame()

# === MOEX API session ===
session = requests.Session()
session.headers.update({"User-Agent": "python-requests/iss-moex-script"})

# === –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ XML TQOB –∏ TQCB (—É—Å—Ç–æ–π—á–∏–≤—ã–π –ø–∞—Ä—Å–∏–Ω–≥) ===
@st.cache_data(ttl=3600)
def fetch_board_xml(board: str):
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç XML-–≤—ã–≥—Ä—É–∑–∫—É MOEX –¥–ª—è board (tqob/tqcb) –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å ISIN -> –∞—Ç—Ä–∏–±—É—Ç–Ω–∞—è –∫–∞—Ä—Ç–∞ (dict)
    –î–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã –º—ã —Å–æ—Ö—Ä–∞–Ω—è–µ–º secid –∏ emitterid (–µ—Å–ª–∏ –µ—Å—Ç—å).
    """
    url = f"https://iss.moex.com/iss/engines/stock/markets/bonds/boards/{board.lower()}/securities.xml?marketprice_board=3&iss.meta=off"
    try:
        r = session.get(url, timeout=20)
        r.raise_for_status()
        xml_content = r.content.decode("utf-8", errors="ignore")

        # —É–±—Ä–∞—Ç—å namespace, –µ—Å–ª–∏ –µ—Å—Ç—å (–ø–æ–∑–≤–æ–ª—è–µ—Ç –±–µ–∑–æ–ø–∞—Å–Ω–æ –ø–∞—Ä—Å–∏—Ç—å —Ç–µ–≥ row)
        xml_content = re.sub(r'\sxmlns="[^"]+"', "", xml_content, count=1)
        root = ET.fromstring(xml_content)

        mapping = {}  # ISIN -> { "SECID": secid, "EMITTERID": emitterid, ... }
        for el in root.iter():
            # —Ç–µ–≥ –º–æ–∂–µ—Ç –±—ã—Ç—å '{...}row' ‚Äî –ø—Ä–æ–≤–µ—Ä—è–µ–º –æ–∫–æ–Ω—á–∞–Ω–∏–µ
            if el.tag.lower().endswith("row"):
                # –ø—Ä–∏–≤–æ–¥–∏–º –∫–ª—é—á–∏ –∞—Ç—Ä–∏–±—É—Ç–æ–≤ –∫ –≤–µ—Ä—Ö–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
                attrs = {k.upper(): v for k, v in el.attrib.items()}
                isin = attrs.get("ISIN", "").strip().upper()
                secid = attrs.get("SECID", "").strip().upper()
                emitterid = attrs.get("EMITTERID", "").strip()
                if isin:
                    mapping[isin] = {"SECID": secid or None, "EMITTERID": emitterid or None, **attrs}
        return mapping
    except Exception as e:
        st.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å {board}: {e}")
        return {}

TQOB_MAP = fetch_board_xml("tqob")
TQCB_MAP = fetch_board_xml("tqcb")

# –æ—Ç–ª–∞–¥–æ—á–Ω—ã–π –≤—ã–≤–æ–¥ (—É–¥–∞–ª–∏ –∏–ª–∏ –∑–∞–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π –≤ –ø—Ä–æ–¥–∞–∫—à–Ω)
st.write("üîé –ü—Ä–æ–≤–µ—Ä–∫–∞ TQOB (–ø—Ä–∏–º–µ—Ä):", TQOB_MAP.get("RU000A101N52"))

# === –§—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞ —ç–º–∏—Ç–µ–Ω—Ç–∞ –∏ SECID ===
@st.cache_data(ttl=3600)
def fetch_emitter_and_secid(isin: str):
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (emitter_id, secid).
    –õ–æ–≥–∏–∫–∞:
      1) –ø—Ä—è–º–æ–π –∑–∞–ø—Ä–æ—Å /iss/securities/{isin}.json
      2) –ø—Ä—è–º–æ–π xml /iss/securities/{isin}.xml
      3) –ø–æ–∏—Å–∫ –≤ TQOB/TQCB –º–∞–ø–∞—Ö
      4) –ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ /iss/securities.json?q={isin}
    """
    isin = str(isin).strip().upper()
    if not isin:
        return None, None

    emitter_id = None
    secid = None

    # --- 1) –ø—Ä—è–º–æ–π JSON ---
    try:
        url = f"https://iss.moex.com/iss/securities/{isin}.json"
        r = session.get(url, timeout=10)
        r.raise_for_status()
        data = r.json()
        securities = data.get("securities", {})
        cols = securities.get("columns", [])
        rows = securities.get("data", [])
        if rows:
            # –±–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É
            first = rows[0]
            col_map = {c.upper(): i for i, c in enumerate(cols)}
            if "EMITTER_ID" in col_map:
                emitter_id = first[col_map["EMITTER_ID"]]
            if "SECID" in col_map:
                secid = first[col_map["SECID"]]
    except Exception:
        # –º–æ–ª—á–∞ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º ‚Äî –ø–µ—Ä–µ—Ö–æ–¥–∏ –∫ —Å–ª–µ–¥—É—é—â–µ–º—É —à–∞–≥—É
        pass

    # --- 2) –ø—Ä—è–º–æ–π XML ---
    if not emitter_id or not secid:
        try:
            url = f"https://iss.moex.com/iss/securities/{isin}.xml?iss.meta=off"
            r = session.get(url, timeout=10)
            r.raise_for_status()
            # –≤–æ–∑–º–æ–∂–Ω–æ –µ—Å—Ç—å namespace ‚Äî —É–¥–∞–ª—è–µ–º
            xml_content = r.content.decode("utf-8", errors="ignore")
            xml_content = re.sub(r'\sxmlns="[^"]+"', "", xml_content, count=1)
            root = ET.fromstring(xml_content)
            # –ø–æ–∏—Å–∫ –ø–∞—Ä 'name'='EMITTER_ID' –∏ 'name'='SECID' –≤ result xml
            for node in root.iter():
                # —ç–ª–µ–º–µ–Ω—Ç—ã –≤ xml –º–æ–≥—É—Ç –∏–º–µ—Ç—å –∞—Ç—Ä–∏–±—É—Ç—ã name / value
                name_attr = (node.attrib.get("name") or node.attrib.get("NAME") or "").strip().upper()
                value_attr = (node.attrib.get("value") or node.attrib.get("VALUE") or "").strip()
                if name_attr == "EMITTER_ID" and not emitter_id:
                    emitter_id = value_attr
                if name_attr == "SECID" and not secid:
                    secid = value_attr
                # –µ—Å–ª–∏ –Ω–∞—à–ª–∏ –æ–±–∞ ‚Äî –º–æ–∂–Ω–æ –ø—Ä–µ—Ä–≤–∞—Ç—å
                if emitter_id and secid:
                    break
        except Exception:
            pass

    # --- 3) –ø–æ–∏—Å–∫ –≤ TQOB / TQCB ---
    if not secid:
        m = TQOB_MAP.get(isin)
        if m and m.get("SECID"):
            secid = m.get("SECID")
            if not emitter_id:
                emitter_id = m.get("EMITTERID")
        else:
            m2 = TQCB_MAP.get(isin)
            if m2 and m2.get("SECID"):
                secid = m2.get("SECID")
                if not emitter_id:
                    emitter_id = m2.get("EMITTERID")

    # --- 4) –≥–ª–æ–±–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ q= (–∏–Ω–æ–≥–¥–∞ –ø–æ–º–æ–≥–∞–µ—Ç) ---
    if not secid:
        try:
            url = f"https://iss.moex.com/iss/securities.json?q={isin}&iss.meta=off"
            r = session.get(url, timeout=10)
            r.raise_for_status()
            data = r.json()
            securities = data.get("securities", {})
            cols = securities.get("columns", [])
            rows = securities.get("data", [])
            if rows:
                col_map = {c.upper(): i for i, c in enumerate(cols)}
                for row in rows:
                    # –∏–Ω–æ–≥–¥–∞ isin –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ —Ç–æ—á–Ω—ã–º - –ø—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ö–æ–∂–¥–µ–Ω–∏–µ
                    row_isin = None
                    if "ISIN" in col_map:
                        row_isin = (row[col_map["ISIN"]] or "").strip().upper()
                    if row_isin == isin or isin in [str(x).strip().upper() for x in row]:
                        if "SECID" in col_map:
                            secid = row[col_map["SECID"]]
                        if "EMITTER_ID" in col_map and not emitter_id:
                            emitter_id = row[col_map["EMITTER_ID"]]
                        if secid:
                            break
        except Exception:
            pass

    # –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –≤ None
    if emitter_id == "":
        emitter_id = None
    if secid == "":
        secid = None

    return emitter_id, secid

# === –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –ø–æ ISIN ===
def get_bond_data(isin):
    try:
        emitter_id, secid = fetch_emitter_and_secid(isin)
        secname = maturity_date = put_date = call_date = None
        record_date = coupon_date = None

        # --- –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –±—É–º–∞–≥–µ –ø–æ SECID ---
        if secid:
            try:
                url_info = f"https://iss.moex.com/iss/engines/stock/markets/bonds/securities/{secid}.json"
                r = session.get(url_info, timeout=10)
                if r.status_code == 200:
                    data_info = r.json()
                    rows_info = data_info.get("securities", {}).get("data", [])
                    cols_info = data_info.get("securities", {}).get("columns", [])
                    if rows_info:
                        info = dict(zip(cols_info, rows_info[0]))
                        # –∫–ª—é—á–∏ –≤ JSON –ø—Ä–∏—Ö–æ–¥—è—Ç –≤ –∏—Å—Ö–æ–¥–Ω–æ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–∞–∫ –µ—Å—Ç—å –∏ –≤ upper-–≤–µ—Ä—Å–∏–∏
                        secname = info.get("SECNAME") or info.get("SEC_NAME") or info.get("SECNAME".lower())
                        maturity_date = info.get("MATDATE")
                        put_date = info.get("PUTOPTIONDATE")
                        call_date = info.get("CALLOPTIONDATE")
            except Exception:
                pass

        # --- –ö—É–ø–æ–Ω—ã ---
        if secid:
            try:
                url_coupons = f"https://iss.moex.com/iss/statistics/engines/stock/markets/bonds/bondization/{secid}.json?iss.only=coupons&iss.meta=off"
                r = session.get(url_coupons, timeout=10)
                r.raise_for_status()
                data_coupons = r.json()
                coupons = data_coupons.get("coupons", {}).get("data", [])
                columns_coupons = data_coupons.get("coupons", {}).get("columns", [])
                if coupons:
                    df_coupons = pd.DataFrame(coupons, columns=columns_coupons)
                    today = pd.to_datetime(datetime.today().date())

                    def next_date(col):
                        if col in df_coupons:
                            future = pd.to_datetime(df_coupons[col], errors="coerce")
                            future = future[future >= today]
                            return future.min() if not future.empty else None
                        return None

                    record_date = next_date("recorddate")
                    coupon_date = next_date("coupondate")
            except Exception:
                pass

        def fmt(date):
            if pd.isna(date) or not date:
                return None
            try:
                return pd.to_datetime(date).strftime("%Y-%m-%d")
            except Exception:
                return None

        return {
            "ISIN": isin,
            "–ö–æ–¥ —ç–º–∏—Ç–µ–Ω—Ç–∞": emitter_id or "",
            "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞": secname or "",
            "–î–∞—Ç–∞ –ø–æ–≥–∞—à–µ–Ω–∏—è": fmt(maturity_date),
            "–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Put": fmt(put_date),
            "–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Call": fmt(call_date),
            "–î–∞—Ç–∞ —Ñ–∏–∫—Å–∞—Ü–∏–∏ –∫—É–ø–æ–Ω–∞": fmt(record_date),
            "–î–∞—Ç–∞ –∫—É–ø–æ–Ω–∞": fmt(coupon_date),
        }

    except Exception as e:
        st.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {isin}: {e}")
        return {
            "ISIN": isin,
            "–ö–æ–¥ —ç–º–∏—Ç–µ–Ω—Ç–∞": "",
            "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞": "",
            "–î–∞—Ç–∞ –ø–æ–≥–∞—à–µ–Ω–∏—è": None,
            "–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Put": None,
            "–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Call": None,
            "–î–∞—Ç–∞ —Ñ–∏–∫—Å–∞—Ü–∏–∏ –∫—É–ø–æ–Ω–∞": None,
            "–î–∞—Ç–∞ –∫—É–ø–æ–Ω–∞": None,
        }

# === –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ ===
def fetch_isins_parallel(isins):
    results = []
    with ThreadPoolExecutor(max_workers=10) as executor:
        future_to_isin = {executor.submit(get_bond_data, isin): isin for isin in isins}
        for future in as_completed(future_to_isin):
            data = future.result()
            if data:
                results.append(data)
    return results

# === –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –≤–≤–æ–¥–∞ ===
st.subheader("üì§ –ó–∞–≥—Ä—É–∑–∫–∞ –∏–ª–∏ –≤–≤–æ–¥ ISIN")
tab1, tab2 = st.tabs(["üìÅ –ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª", "‚úçÔ∏è –í–≤–µ—Å—Ç–∏ –≤—Ä—É—á–Ω—É—é"])

with tab1:
    uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ Excel –∏–ª–∏ CSV —Å –∫–æ–ª–æ–Ω–∫–æ–π ISIN", type=["xlsx", "xls", "csv"])

with tab2:
    isin_input = st.text_area("–í–≤–µ–¥–∏—Ç–µ –∏–ª–∏ –≤—Å—Ç–∞–≤—å—Ç–µ ISIN (—á–µ—Ä–µ–∑ Ctrl+V, –ø—Ä–æ–±–µ–ª –∏–ª–∏ –∑–∞–ø—è—Ç—É—é)", height=150)
    if st.button("üîç –ü–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –ø–æ –≤–≤–µ–¥—ë–Ω–Ω—ã–º ISIN"):
        raw_text = isin_input.strip()
        if raw_text:
            isins = re.split(r"[\s,;]+", raw_text)
            isins = [i.strip().upper() for i in isins if i.strip()]
            results = fetch_isins_parallel(isins)
            st.session_state["results"] = pd.DataFrame(results)
            st.success("‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω—ã!")

# === –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞ ===
if uploaded_file:
    if not st.session_state["file_loaded"] or uploaded_file.name != st.session_state["last_file_name"]:
        st.session_state["file_loaded"] = True
        st.session_state["last_file_name"] = uploaded_file.name
        try:
            if uploaded_file.name.lower().endswith(".csv"):
                df = pd.read_csv(uploaded_file, dtype=str)
            else:
                df = pd.read_excel(uploaded_file, dtype=str)
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞: {e}")
            st.stop()

        df.columns = [c.strip().upper() for c in df.columns]
        if "ISIN" not in df.columns:
            st.error("‚ùå –í —Ñ–∞–π–ª–µ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –∫–æ–ª–æ–Ω–∫–∞ 'ISIN'.")
            st.stop()
        isins = df["ISIN"].dropna().unique().tolist()
        isins = [str(x).strip().upper() for x in isins if str(x).strip()]
        results = fetch_isins_parallel(isins)
        st.session_state["results"] = pd.DataFrame(results)
        st.success("‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω—ã –∏–∑ —Ñ–∞–π–ª–∞!")

# === –ü–æ–¥–≥—Ä—É–∑–∫–∞ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∞ —ç–º–∏—Ç–µ–Ω—Ç–æ–≤ ===
@st.cache_data(ttl=3600)
def fetch_emitter_names():
    url = "https://raw.githubusercontent.com/mainarkler/Bond_date/refs/heads/main/Pifagr_name_with_emitter.csv"
    try:
        df_emitters = pd.read_csv(url, dtype=str)
        df_emitters.columns = [c.strip() for c in df_emitters.columns]
        return df_emitters
    except Exception as e:
        st.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫ —ç–º–∏—Ç–µ–Ω—Ç–æ–≤: {e}")
        return pd.DataFrame(columns=["Issuer", "EMITTER_ID"])

df_emitters = fetch_emitter_names()

# === –°—Ç–∏–ª–∏–∑–∞—Ü–∏—è —Ç–∞–±–ª–∏—Ü—ã ===
def style_df(row):
    if pd.isna(row.get("–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞")) or row.get("–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞") in [None, "None", ""]:
        return ["background-color: DimGray; color: white"] * len(row)
    today = datetime.today().date()
    danger_threshold = today + timedelta(days=days_threshold)
    key_dates = ["–î–∞—Ç–∞ –ø–æ–≥–∞—à–µ–Ω–∏—è", "–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Put", "–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Call", "–î–∞—Ç–∞ —Ñ–∏–∫—Å–∞—Ü–∏–∏ –∫—É–ø–æ–Ω–∞", "–î–∞—Ç–∞ –∫—É–ø–æ–Ω–∞"]
    colors = ["" for _ in row]
    for i, col in enumerate(row.index):
        if col in key_dates and pd.notnull(row[col]):
            try:
                d = pd.to_datetime(row[col]).date()
                if d <= danger_threshold:
                    colors[i] = "background-color: Chocolate"
            except:
                pass
    if any(c == "background-color: Chocolate" for c in colors):
        colors = ["background-color: SandyBrown" if c == "" else c for c in colors]
    return colors

# === –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ===
if st.session_state["results"] is not None:
    df_res = st.session_state["results"].copy()

    if "–ö–æ–¥ —ç–º–∏—Ç–µ–Ω—Ç–∞" in df_res.columns and not df_emitters.empty:
        df_res = df_res.merge(df_emitters, how="left", left_on="–ö–æ–¥ —ç–º–∏—Ç–µ–Ω—Ç–∞", right_on="EMITTER_ID")
        df_res["–≠–º–∏—Ç–µ–Ω—Ç"] = df_res["Issuer"]
        df_res.drop(columns=["Issuer", "EMITTER_ID"], inplace=True, errors="ignore")

        cols = df_res.columns.tolist()
        if "–≠–º–∏—Ç–µ–Ω—Ç" in cols and "–ö–æ–¥ —ç–º–∏—Ç–µ–Ω—Ç–∞" in cols:
            cols.remove("–≠–º–∏—Ç–µ–Ω—Ç")
            idx = cols.index("–ö–æ–¥ —ç–º–∏—Ç–µ–Ω—Ç–∞")
            cols.insert(idx + 1, "–≠–º–∏—Ç–µ–Ω—Ç")
            df_res = df_res[cols]

        st.session_state["results"] = df_res
    else:
        st.warning("‚ö†Ô∏è –í –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ '–ö–æ–¥ —ç–º–∏—Ç–µ–Ω—Ç–∞' ‚Äî –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å–æ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–æ–º –ø—Ä–æ–ø—É—â–µ–Ω–æ.")

    st.dataframe(df_res.style.apply(style_df, axis=1), use_container_width=True)

    def to_excel(df):
        output = BytesIO()
        with pd.ExcelWriter(output, engine="openpyxl") as writer:
            df.to_excel(writer, index=False, sheet_name="–î–∞–Ω–Ω—ã–µ")
        return output.getvalue()

    st.download_button(
        label="üíæ –°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç (Excel)",
        data=to_excel(df_res),
        file_name="bond_data.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
    )
else:
    st.info("üëÜ –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –∏–ª–∏ –≤–≤–µ–¥–∏—Ç–µ ISIN-—ã –≤—Ä—É—á–Ω—É—é.")
